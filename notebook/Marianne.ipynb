{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a9b752",
   "metadata": {},
   "source": [
    "## Data processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf97dfa",
   "metadata": {},
   "source": [
    "Data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5206b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a186dc1",
   "metadata": {},
   "source": [
    "Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a2cb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve file\n",
    "\n",
    "hatespeech = pd.read_csv(\"/home/mariannettrd/code/irismarechal1997/moder_ia/raw_data/230911_Dynamically_Generated_Hate_Speech_01.csv\")\n",
    "\n",
    "hatespeech[\"source\"]=\"230911_Dynamically_Generated_Hate_Speech_01\" # add source of the doc \n",
    "hatespeech = hatespeech[[\"source\", \"text\", \"label\"]] #select columns \n",
    "hatespeech.rename(columns={'label':'offensive'}, inplace=True) # rename column \n",
    "#encore offensive column\n",
    "mapping = {'hate': 1, 'nothate': '0'} \n",
    "\n",
    "hatespeech[\"offensive\"] = hatespeech[\"offensive\"].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee9f89",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Premier data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "693c7b5e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# file_path = \"home/mariannettrd/code/irismarechal1997/moder_ia/raw_data/230911_ConvAbuseEMNLPfull.csv\"\n",
    "# file_path = \"home\\mariannettrd\\code\\irismarechal1997\\moder_ia\\raw_data\\230911_ConvAbuseEMNLPfull.csv\"\n",
    "file_path = \"/home/mariannettrd/code/irismarechal1997/moder_ia/raw_data/230911_Dynamically_Generated_Hate_Speech_01.csv\"\n",
    "hatespeech = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd668a5a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>model_wrong</th>\n",
       "      <th>db.model_preds</th>\n",
       "      <th>status</th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97457</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10001</td>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>False</td>\n",
       "      <td>0.08233</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10002</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.92319</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10003</td>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99006</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004</td>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98836</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40618</th>\n",
       "      <td>40736</td>\n",
       "      <td>9995</td>\n",
       "      <td>we should forcibly remove all the foreigners f...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.86945</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40619</th>\n",
       "      <td>40737</td>\n",
       "      <td>9996</td>\n",
       "      <td>we should forcibly remove all the immigrants f...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50039</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40620</th>\n",
       "      <td>40738</td>\n",
       "      <td>9997</td>\n",
       "      <td>dalits are unworthy of the Gods love</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97652</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40621</th>\n",
       "      <td>40739</td>\n",
       "      <td>9998</td>\n",
       "      <td>dalits are worthless</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.94326</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40622</th>\n",
       "      <td>40740</td>\n",
       "      <td>9999</td>\n",
       "      <td>dalits are deserves to be treated as lowlife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.94324</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40623 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                               text  \\\n",
       "0               1  10000  It should be legal for a husband to rape his wife   \n",
       "1               2  10001                            dalits are lowlife scum   \n",
       "2               3  10002                                dalits are lowlives   \n",
       "3               4  10003  It was a better world when women dare not ques...   \n",
       "4               5  10004  I don't work this hard so that those immigrant...   \n",
       "...           ...    ...                                                ...   \n",
       "40618       40736   9995  we should forcibly remove all the foreigners f...   \n",
       "40619       40737   9996  we should forcibly remove all the immigrants f...   \n",
       "40620       40738   9997               dalits are unworthy of the Gods love   \n",
       "40621       40739   9998                               dalits are worthless   \n",
       "40622       40740   9999       dalits are deserves to be treated as lowlife   \n",
       "\n",
       "      label      type model_wrong  db.model_preds           status round  \\\n",
       "0      hate  notgiven        True         0.97457  dynabench entry     1   \n",
       "1      hate  notgiven       False         0.08233  dynabench entry     1   \n",
       "2      hate  notgiven        True         0.92319  dynabench entry     1   \n",
       "3      hate  notgiven        True         0.99006  dynabench entry     1   \n",
       "4      hate  notgiven        True         0.98836  dynabench entry     1   \n",
       "...     ...       ...         ...             ...              ...   ...   \n",
       "40618  hate  notgiven        True         0.86945  dynabench entry     1   \n",
       "40619  hate  notgiven        True         0.50039  dynabench entry     1   \n",
       "40620  hate  notgiven        True         0.97652  dynabench entry     1   \n",
       "40621  hate  notgiven        True         0.94326  dynabench entry     1   \n",
       "40622  hate  notgiven        True         0.94324  dynabench entry     1   \n",
       "\n",
       "       split   annotator  \n",
       "0      train  gnzuctwed3  \n",
       "1       test  cagnluiznm  \n",
       "2      train  cagnluiznm  \n",
       "3       test  gnzuctwed3  \n",
       "4      train  cagnluiznm  \n",
       "...      ...         ...  \n",
       "40618  train  cagnluiznm  \n",
       "40619  train  cagnluiznm  \n",
       "40620  train  cagnluiznm  \n",
       "40621  train  cagnluiznm  \n",
       "40622  train  cagnluiznm  \n",
       "\n",
       "[40623 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatespeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e23f59b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hatespeech[\"source\"]=\"230911_Dynamically_Generated_Hate_Speech_01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac1fdba6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>model_wrong</th>\n",
       "      <th>db.model_preds</th>\n",
       "      <th>status</th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>annotator</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97457</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10001</td>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>False</td>\n",
       "      <td>0.08233</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>cagnluiznm</td>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10002</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.92319</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10003</td>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99006</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004</td>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98836</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                               text label  \\\n",
       "0           1  10000  It should be legal for a husband to rape his wife  hate   \n",
       "1           2  10001                            dalits are lowlife scum  hate   \n",
       "2           3  10002                                dalits are lowlives  hate   \n",
       "3           4  10003  It was a better world when women dare not ques...  hate   \n",
       "4           5  10004  I don't work this hard so that those immigrant...  hate   \n",
       "\n",
       "       type model_wrong  db.model_preds           status round  split  \\\n",
       "0  notgiven        True         0.97457  dynabench entry     1  train   \n",
       "1  notgiven       False         0.08233  dynabench entry     1   test   \n",
       "2  notgiven        True         0.92319  dynabench entry     1  train   \n",
       "3  notgiven        True         0.99006  dynabench entry     1   test   \n",
       "4  notgiven        True         0.98836  dynabench entry     1  train   \n",
       "\n",
       "    annotator                                       source  \n",
       "0  gnzuctwed3  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "1  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "2  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "3  gnzuctwed3  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "4  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatespeech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b873b908",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        Unnamed: 0     id                                               text  \\\n",
       "0               1  10000  It should be legal for a husband to rape his wife   \n",
       "1               2  10001                            dalits are lowlife scum   \n",
       "2               3  10002                                dalits are lowlives   \n",
       "3               4  10003  It was a better world when women dare not ques...   \n",
       "4               5  10004  I don't work this hard so that those immigrant...   \n",
       "...           ...    ...                                                ...   \n",
       "40618       40736   9995  we should forcibly remove all the foreigners f...   \n",
       "40619       40737   9996  we should forcibly remove all the immigrants f...   \n",
       "40620       40738   9997               dalits are unworthy of the Gods love   \n",
       "40621       40739   9998                               dalits are worthless   \n",
       "40622       40740   9999       dalits are deserves to be treated as lowlife   \n",
       "\n",
       "      label      type model_wrong  db.model_preds           status round  \\\n",
       "0      hate  notgiven        True         0.97457  dynabench entry     1   \n",
       "1      hate  notgiven       False         0.08233  dynabench entry     1   \n",
       "2      hate  notgiven        True         0.92319  dynabench entry     1   \n",
       "3      hate  notgiven        True         0.99006  dynabench entry     1   \n",
       "4      hate  notgiven        True         0.98836  dynabench entry     1   \n",
       "...     ...       ...         ...             ...              ...   ...   \n",
       "40618  hate  notgiven        True         0.86945  dynabench entry     1   \n",
       "40619  hate  notgiven        True         0.50039  dynabench entry     1   \n",
       "40620  hate  notgiven        True         0.97652  dynabench entry     1   \n",
       "40621  hate  notgiven        True         0.94326  dynabench entry     1   \n",
       "40622  hate  notgiven        True         0.94324  dynabench entry     1   \n",
       "\n",
       "       split   annotator                                       source  \n",
       "0      train  gnzuctwed3  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "1       test  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "2      train  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "3       test  gnzuctwed3  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "4      train  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "...      ...         ...                                          ...  \n",
       "40618  train  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "40619  train  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "40620  train  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "40621  train  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "40622  train  cagnluiznm  230911_Dynamically_Generated_Hate_Speech_01  \n",
       "\n",
       "[40623 rows x 12 columns]>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatespeech.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bb0cd57",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40623, 12)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatespeech.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1be7a4cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          int64\n",
       "id                 object\n",
       "text               object\n",
       "label              object\n",
       "type               object\n",
       "model_wrong        object\n",
       "db.model_preds    float64\n",
       "status             object\n",
       "round              object\n",
       "split              object\n",
       "annotator          object\n",
       "source             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatespeech.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef4bfd5e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hatespeech = hatespeech[[\"source\", \"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dffe09f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40618</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>we should forcibly remove all the foreigners f...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40619</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>we should forcibly remove all the immigrants f...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40620</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>dalits are unworthy of the Gods love</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40621</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>dalits are worthless</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40622</th>\n",
       "      <td>230911_Dynamically_Generated_Hate_Speech_01</td>\n",
       "      <td>dalits are deserves to be treated as lowlife</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40623 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            source  \\\n",
       "0      230911_Dynamically_Generated_Hate_Speech_01   \n",
       "1      230911_Dynamically_Generated_Hate_Speech_01   \n",
       "2      230911_Dynamically_Generated_Hate_Speech_01   \n",
       "3      230911_Dynamically_Generated_Hate_Speech_01   \n",
       "4      230911_Dynamically_Generated_Hate_Speech_01   \n",
       "...                                            ...   \n",
       "40618  230911_Dynamically_Generated_Hate_Speech_01   \n",
       "40619  230911_Dynamically_Generated_Hate_Speech_01   \n",
       "40620  230911_Dynamically_Generated_Hate_Speech_01   \n",
       "40621  230911_Dynamically_Generated_Hate_Speech_01   \n",
       "40622  230911_Dynamically_Generated_Hate_Speech_01   \n",
       "\n",
       "                                                    text label  \n",
       "0      It should be legal for a husband to rape his wife  hate  \n",
       "1                                dalits are lowlife scum  hate  \n",
       "2                                    dalits are lowlives  hate  \n",
       "3      It was a better world when women dare not ques...  hate  \n",
       "4      I don't work this hard so that those immigrant...  hate  \n",
       "...                                                  ...   ...  \n",
       "40618  we should forcibly remove all the foreigners f...  hate  \n",
       "40619  we should forcibly remove all the immigrants f...  hate  \n",
       "40620               dalits are unworthy of the Gods love  hate  \n",
       "40621                               dalits are worthless  hate  \n",
       "40622       dalits are deserves to be treated as lowlife  hate  \n",
       "\n",
       "[40623 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatespeech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adb144",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### hatespeech.rename(columns={'label':'offensive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15b3a691",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5569/1591395345.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hatespeech.rename(columns={'label':'offensive'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "hatespeech.rename(columns={'label':'offensive'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6d97992",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hate', 'nothate'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = hatespeech['offensive'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e6308",
   "metadata": {
    "hidden": true
   },
   "source": [
    "hatespeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a39a8163",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5569/733604717.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hatespeech[\"offensive\"] = hatespeech[\"offensive\"].map(mapping)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mapping = {'hate': 1, 'nothate': '0'}\n",
    "hatespeech[\"offensive\"] = hatespeech[\"offensive\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73fc915",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc07bfb0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#retrieve file\n",
    "file_path = \"/home/mariannettrd/code/irismarechal1997/moder_ia/raw_data/230911_Dynamically_Generated_Hate_Speech_01.csv\"\n",
    "hatespeech = pd.read_csv(file_path)\n",
    "\n",
    "hatespeech[\"source\"]=\"230911_Dynamically_Generated_Hate_Speech_01\" # add source of the doc \n",
    "hatespeech = hatespeech[[\"source\", \"text\", \"label\"]] #select columns \n",
    "hatespeech.rename(columns={'label':'offensive'}, inplace=True) # rename column \n",
    "#encore offensive column\n",
    "mapping = {'hate': 1, 'nothate': '0'} \n",
    "\n",
    "hatespeech[\"offensive\"] = hatespeech[\"offensive\"].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f24fb92",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## deuxième dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f7c0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bfe2301",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hateXplain = pd.read_json(\"/home/mariannettrd/code/irismarechal1997/moder_ia/raw_data/230911_HateXplain.json\")\n",
    "\n",
    "hateXplain_inversed = hateXplain.transpose()\n",
    "\n",
    "hateXplain=hateXplain_inversed\n",
    "\n",
    "\n",
    "hateXplain[\"source\"]=\"230911_HateXplain\" # add source of the doc\n",
    "\n",
    "\n",
    "hateXplain = hateXplain[[\"post_tokens\", \"annotators\", \"source\"]].copy()\n",
    "\n",
    "hateXplain.reset_index(inplace=True, drop=True)\n",
    "\n",
    "hateXplain[\"offensive\"]=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc2e02ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>annotators</th>\n",
       "      <th>source</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[we, cannot, continue, calling, ourselves, fem...</td>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nawt, yall, niggers, ignoring, me]</td>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 4, 'targe...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[&lt;user&gt;, i, am, bit, confused, coz, chinese, p...</td>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 1, 't...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[this, bitch, in, whataburger, eating, a, burg...</td>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 4, 't...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         post_tokens  \\\n",
       "0  [i, dont, think, im, getting, my, baby, them, ...   \n",
       "1  [we, cannot, continue, calling, ourselves, fem...   \n",
       "2                [nawt, yall, niggers, ignoring, me]   \n",
       "3  [<user>, i, am, bit, confused, coz, chinese, p...   \n",
       "4  [this, bitch, in, whataburger, eating, a, burg...   \n",
       "\n",
       "                                          annotators             source  \\\n",
       "0  [{'label': 'normal', 'annotator_id': 1, 'targe...  230911_HateXplain   \n",
       "1  [{'label': 'normal', 'annotator_id': 1, 'targe...  230911_HateXplain   \n",
       "2  [{'label': 'normal', 'annotator_id': 4, 'targe...  230911_HateXplain   \n",
       "3  [{'label': 'hatespeech', 'annotator_id': 1, 't...  230911_HateXplain   \n",
       "4  [{'label': 'hatespeech', 'annotator_id': 4, 't...  230911_HateXplain   \n",
       "\n",
       "   offensive  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hateXplain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b56c156",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for i in range(0,len(hateXplain)): \n",
    "#     hateXplain.iloc[i,-1]= hateXplain.iloc[i,1][0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0740b5df",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "20143    1\n",
       "20144    1\n",
       "20145    1\n",
       "20146    1\n",
       "20147    1\n",
       "Name: offensive, Length: 20148, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hateXplain[\"offensive\"]=hateXplain[\"annotators\"].apply(lambda x:x[0][\"label\"]).apply(lambda x:0 if x ==\"normal\" else 1)\n",
    "hateXplain[\"offensive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "916917cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>annotators</th>\n",
       "      <th>source</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[we, cannot, continue, calling, ourselves, fem...</td>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 1, 'targe...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nawt, yall, niggers, ignoring, me]</td>\n",
       "      <td>[{'label': 'normal', 'annotator_id': 4, 'targe...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[&lt;user&gt;, i, am, bit, confused, coz, chinese, p...</td>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 1, 't...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[this, bitch, in, whataburger, eating, a, burg...</td>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 4, 't...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>[if, ur, still, on, twitter, tell, carlton, i,...</td>\n",
       "      <td>[{'label': 'offensive', 'annotator_id': 217, '...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>[when, i, first, got, on, here, and, said, i, ...</td>\n",
       "      <td>[{'label': 'offensive', 'annotator_id': 220, '...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>[was, macht, der, moslem, wenn, der, zion, geg...</td>\n",
       "      <td>[{'label': 'offensive', 'annotator_id': 206, '...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>[it, is, awful, look, at, world, demographics,...</td>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 209, ...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>[the, jewish, globalist, elite, have, only, im...</td>\n",
       "      <td>[{'label': 'hatespeech', 'annotator_id': 200, ...</td>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20148 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_tokens  \\\n",
       "0      [i, dont, think, im, getting, my, baby, them, ...   \n",
       "1      [we, cannot, continue, calling, ourselves, fem...   \n",
       "2                    [nawt, yall, niggers, ignoring, me]   \n",
       "3      [<user>, i, am, bit, confused, coz, chinese, p...   \n",
       "4      [this, bitch, in, whataburger, eating, a, burg...   \n",
       "...                                                  ...   \n",
       "20143  [if, ur, still, on, twitter, tell, carlton, i,...   \n",
       "20144  [when, i, first, got, on, here, and, said, i, ...   \n",
       "20145  [was, macht, der, moslem, wenn, der, zion, geg...   \n",
       "20146  [it, is, awful, look, at, world, demographics,...   \n",
       "20147  [the, jewish, globalist, elite, have, only, im...   \n",
       "\n",
       "                                              annotators             source  \\\n",
       "0      [{'label': 'normal', 'annotator_id': 1, 'targe...  230911_HateXplain   \n",
       "1      [{'label': 'normal', 'annotator_id': 1, 'targe...  230911_HateXplain   \n",
       "2      [{'label': 'normal', 'annotator_id': 4, 'targe...  230911_HateXplain   \n",
       "3      [{'label': 'hatespeech', 'annotator_id': 1, 't...  230911_HateXplain   \n",
       "4      [{'label': 'hatespeech', 'annotator_id': 4, 't...  230911_HateXplain   \n",
       "...                                                  ...                ...   \n",
       "20143  [{'label': 'offensive', 'annotator_id': 217, '...  230911_HateXplain   \n",
       "20144  [{'label': 'offensive', 'annotator_id': 220, '...  230911_HateXplain   \n",
       "20145  [{'label': 'offensive', 'annotator_id': 206, '...  230911_HateXplain   \n",
       "20146  [{'label': 'hatespeech', 'annotator_id': 209, ...  230911_HateXplain   \n",
       "20147  [{'label': 'hatespeech', 'annotator_id': 200, ...  230911_HateXplain   \n",
       "\n",
       "       offensive  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  \n",
       "...          ...  \n",
       "20143          1  \n",
       "20144          1  \n",
       "20145          1  \n",
       "20146          1  \n",
       "20147          1  \n",
       "\n",
       "[20148 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hateXplain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01630069",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Naive bayes algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4a4f291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          source  \\\n",
       "0  Hate_Speech_Classification_01   \n",
       "1  Hate_Speech_Classification_01   \n",
       "2  Hate_Speech_Classification_01   \n",
       "3  Hate_Speech_Classification_01   \n",
       "4  Hate_Speech_Classification_01   \n",
       "\n",
       "                                                text  offensive  \n",
       "0                                dalits are lowlives          1  \n",
       "1             gay people are a burden to our society          1  \n",
       "2                              Arabs are not welcome          1  \n",
       "3  I'm not saying we should actually eliminate he...          1  \n",
       "4                       bananas are for black people          1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"/home/mariannettrd/code/irismarechal1997/moder_ia/raw_data/clean_dataset_v2.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1b65272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab1c3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_table(data:pd.DataFrame):\n",
    "        data = data.drop_duplicates() # Remove duplicates\n",
    "        data = data.dropna(subset=['offensive']) # Remove n.a. values in columns 'Label' => check column\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba9ecf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103374</th>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>if ur still on twitter tell carlton i said his...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103375</th>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>when i first got on here and said i hate trump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103376</th>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>was macht der moslem wenn der zion gegen seine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103377</th>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>it is awful look at world demographics asians ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103378</th>\n",
       "      <td>230911_HateXplain</td>\n",
       "      <td>the jewish globalist elite have only imported ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103379 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               source  \\\n",
       "0       Hate_Speech_Classification_01   \n",
       "1       Hate_Speech_Classification_01   \n",
       "2       Hate_Speech_Classification_01   \n",
       "3       Hate_Speech_Classification_01   \n",
       "4       Hate_Speech_Classification_01   \n",
       "...                               ...   \n",
       "103374              230911_HateXplain   \n",
       "103375              230911_HateXplain   \n",
       "103376              230911_HateXplain   \n",
       "103377              230911_HateXplain   \n",
       "103378              230911_HateXplain   \n",
       "\n",
       "                                                     text  offensive  \n",
       "0                                     dalits are lowlives          1  \n",
       "1                  gay people are a burden to our society          1  \n",
       "2                                   Arabs are not welcome          1  \n",
       "3       I'm not saying we should actually eliminate he...          1  \n",
       "4                            bananas are for black people          1  \n",
       "...                                                   ...        ...  \n",
       "103374  if ur still on twitter tell carlton i said his...          1  \n",
       "103375  when i first got on here and said i hate trump...          1  \n",
       "103376  was macht der moslem wenn der zion gegen seine...          1  \n",
       "103377  it is awful look at world demographics asians ...          1  \n",
       "103378  the jewish globalist elite have only imported ...          1  \n",
       "\n",
       "[103379 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = cleaning_table(raw_data)\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58188f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string # \"string\" module is already installed with Python\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "432dbe75",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1647869796.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[60], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    remove rt\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def cleaning_text(data):\n",
    "    sentence = data[\"text\"]\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "\n",
    "    remove rt\n",
    "    \n",
    "    \n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    \n",
    "\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "\n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized)\n",
    "\n",
    "    return cleaned_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned[\"new\"] = data_cleaned[\"text\"].apply(cleaning_text)\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c679f7-846a-49e3-9c44-c105fb034ae4",
   "metadata": {},
   "source": [
    "## work on vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db894a-e449-46b6-822d-11c651144ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "301a6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60dbebbc-cb7b-4cac-ba84-94e08eb8faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = pd.read_csv(\"/home/mariannettrd/code/irismarechal1997/moder_ia/data/processed_dataset_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e29ce90d-998a-4ebd-866a-e6ae90de785d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>1</td>\n",
       "      <td>dalits be lowlives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>1</td>\n",
       "      <td>gay people be a burden to our society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>1</td>\n",
       "      <td>arabs be not welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>1</td>\n",
       "      <td>im not say we should actually eliminate heebs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>1</td>\n",
       "      <td>bananas be for black people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          source  \\\n",
       "0  Hate_Speech_Classification_01   \n",
       "1  Hate_Speech_Classification_01   \n",
       "2  Hate_Speech_Classification_01   \n",
       "3  Hate_Speech_Classification_01   \n",
       "4  Hate_Speech_Classification_01   \n",
       "\n",
       "                                                text  offensive  \\\n",
       "0                                dalits are lowlives          1   \n",
       "1             gay people are a burden to our society          1   \n",
       "2                              Arabs are not welcome          1   \n",
       "3  I'm not saying we should actually eliminate he...          1   \n",
       "4                       bananas are for black people          1   \n",
       "\n",
       "                                      text_processed  \n",
       "0                                 dalits be lowlives  \n",
       "1              gay people be a burden to our society  \n",
       "2                               arabs be not welcome  \n",
       "3  im not say we should actually eliminate heebs ...  \n",
       "4                        bananas be for black people  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6d1da07-c2af-43a2-aad2-9faf81cf6eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive\n",
       "0    0.63\n",
       "1    0.37\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data_processed[\"offensive\"].value_counts(normalize = True), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c3968b9-667a-4249-b210-995133c202e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169216, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f34edfef-e2a0-48bf-be8b-afcab2de8adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='offensive', ylabel='count'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = \"offensive\",data = data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4223dcb2-a678-4389-be9e-f4270a697930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>1</td>\n",
       "      <td>dalits be lowlives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>1</td>\n",
       "      <td>gay people be a burden to our society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>1</td>\n",
       "      <td>arabs be not welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>1</td>\n",
       "      <td>im not say we should actually eliminate heebs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>1</td>\n",
       "      <td>bananas be for black people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          source  \\\n",
       "0  Hate_Speech_Classification_01   \n",
       "1  Hate_Speech_Classification_01   \n",
       "2  Hate_Speech_Classification_01   \n",
       "3  Hate_Speech_Classification_01   \n",
       "4  Hate_Speech_Classification_01   \n",
       "\n",
       "                                                text  offensive  \\\n",
       "0                                dalits are lowlives          1   \n",
       "1             gay people are a burden to our society          1   \n",
       "2                              Arabs are not welcome          1   \n",
       "3  I'm not saying we should actually eliminate he...          1   \n",
       "4                       bananas are for black people          1   \n",
       "\n",
       "                                      text_processed  \n",
       "0                                 dalits be lowlives  \n",
       "1              gay people be a burden to our society  \n",
       "2                               arabs be not welcome  \n",
       "3  im not say we should actually eliminate heebs ...  \n",
       "4                        bananas be for black people  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "606e75d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169216,)\n",
      "(169216,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature/Target\n",
    "X = data_processed[\"text_processed\"]\n",
    "y = data_processed[\"offensive\"]\n",
    "\n",
    "print(X.shape), print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3a3eade-e98e-4f8f-8458-fc6c15ddfa29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, text, offensive, text_processed]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed[data_processed[\"text_processed\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "271715d9-b392-4b21-b648-801eb82f97c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: text_processed, dtype: object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5fd2fc68-0a8d-4f78-b2c2-9eb44c9b694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        dalits be lowlives\n",
       "1                     gay people be a burden to our society\n",
       "2                                      arabs be not welcome\n",
       "3         im not say we should actually eliminate heebs ...\n",
       "4                               bananas be for black people\n",
       "                                ...                        \n",
       "169211    almost everyone choose long or doki wrl mvps a...\n",
       "169212    youre never too old to get excite about get st...\n",
       "169213    asmr retro massage roleplay with a rubber pape...\n",
       "169214    lamcgillicuddy storyteller patgagnon just avoi...\n",
       "169215    helentbracken me too i dream of the peaceful l...\n",
       "Name: text_processed, Length: 169216, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8adb79fe-882f-4644-a198-73d9c015cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "216f9510-733f-4797-90be-6b41e227eb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>1</td>\n",
       "      <td>dalits be lowlives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>1</td>\n",
       "      <td>gay people be a burden to our society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>1</td>\n",
       "      <td>arabs be not welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>1</td>\n",
       "      <td>im not say we should actually eliminate heebs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>1</td>\n",
       "      <td>bananas be for black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169211</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>Almost everyone chose Long or Doki, WRL MVPs a...</td>\n",
       "      <td>0</td>\n",
       "      <td>almost everyone choose long or doki wrl mvps a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169212</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>You're never too old to get excited about gett...</td>\n",
       "      <td>0</td>\n",
       "      <td>youre never too old to get excite about get st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169213</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>(ASMR) Retro Massage Roleplay With A Rubber Pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>asmr retro massage roleplay with a rubber pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169214</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>@la_mcgillicuddy @storyteller1917 @patgagnon_7...</td>\n",
       "      <td>0</td>\n",
       "      <td>lamcgillicuddy storyteller patgagnon just avoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169215</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>@HelenTBracken Me too!! I dream of the peacefu...</td>\n",
       "      <td>0</td>\n",
       "      <td>helentbracken me too i dream of the peaceful l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169216 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               source  \\\n",
       "0       Hate_Speech_Classification_01   \n",
       "1       Hate_Speech_Classification_01   \n",
       "2       Hate_Speech_Classification_01   \n",
       "3       Hate_Speech_Classification_01   \n",
       "4       Hate_Speech_Classification_01   \n",
       "...                               ...   \n",
       "169211                   Happy_tweets   \n",
       "169212                   Happy_tweets   \n",
       "169213                   Happy_tweets   \n",
       "169214                   Happy_tweets   \n",
       "169215                   Happy_tweets   \n",
       "\n",
       "                                                     text  offensive  \\\n",
       "0                                     dalits are lowlives          1   \n",
       "1                  gay people are a burden to our society          1   \n",
       "2                                   Arabs are not welcome          1   \n",
       "3       I'm not saying we should actually eliminate he...          1   \n",
       "4                            bananas are for black people          1   \n",
       "...                                                   ...        ...   \n",
       "169211  Almost everyone chose Long or Doki, WRL MVPs a...          0   \n",
       "169212  You're never too old to get excited about gett...          0   \n",
       "169213  (ASMR) Retro Massage Roleplay With A Rubber Pa...          0   \n",
       "169214  @la_mcgillicuddy @storyteller1917 @patgagnon_7...          0   \n",
       "169215  @HelenTBracken Me too!! I dream of the peacefu...          0   \n",
       "\n",
       "                                           text_processed  \n",
       "0                                      dalits be lowlives  \n",
       "1                   gay people be a burden to our society  \n",
       "2                                    arabs be not welcome  \n",
       "3       im not say we should actually eliminate heebs ...  \n",
       "4                             bananas be for black people  \n",
       "...                                                   ...  \n",
       "169211  almost everyone choose long or doki wrl mvps a...  \n",
       "169212  youre never too old to get excite about get st...  \n",
       "169213  asmr retro massage roleplay with a rubber pape...  \n",
       "169214  lamcgillicuddy storyteller patgagnon just avoi...  \n",
       "169215  helentbracken me too i dream of the peaceful l...  \n",
       "\n",
       "[169216 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "275fa2f8-970a-4c2d-8bad-1d2896a3bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: text_processed, dtype: object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a0d3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline vectorizer + Naive Bayes\n",
    "pipeline_naive_bayes = make_pipeline(\n",
    "    TfidfVectorizer(), \n",
    "    MultinomialNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3c6decbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation\n",
    "cv_results = cross_validate(pipeline_naive_bayes, X, y, cv = 5, scoring = [\"precision\",\"recall\", \"accuracy\"], error_score='raise')\n",
    "average_precision = cv_results[\"test_precision\"].mean()\n",
    "np.round(average_precision,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16f7c2d1-c87f-492c-a127-2eaae5ef82e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.41765213, 2.40332937, 2.34000897, 2.40153742, 2.29845309]),\n",
       " 'score_time': array([0.52620935, 0.45551729, 0.4841404 , 0.51326847, 0.59507394]),\n",
       " 'test_precision': array([0.50256124, 0.41984084, 0.99816131, 0.99429658, 0.98476454]),\n",
       " 'test_recall': array([0.42595516, 0.54554784, 0.64280076, 0.37156615, 0.16837701]),\n",
       " 'test_accuracy': array([0.62731947, 0.54770558, 0.86585114, 0.76396892, 0.68773454])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9c86d8c-2ab4-4e5b-b4ae-0d1da98ede83",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = round(cv_results[\"test_precision\"].mean(),2)\n",
    "average_recall = round(cv_results[\"test_recall\"].mean(),2)\n",
    "average_accuracy = round(cv_results[\"test_accuracy\"].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b473726-bf64-4b76-bfff-0c9d33cbc66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'precision score is 0.78, recall score is 0.43, accuracy score is 0.7'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'precision score is {average_precision}, recall score is {average_recall}, accuracy score is {average_accuracy}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f0996-38f1-4b15-baa3-2e4152afc88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a746d45b-0678-47de-957a-345dc1757391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vectorized_reviews.shape = (169216, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df = 0.75, max_features = 5000, ngram_range=(1,2))\n",
    "vectorized_reviews = pd.DataFrame(vectorizer.fit_transform(data_processed[\"text_processed\"]).toarray(),\n",
    "                                 columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "print(f\" vectorized_reviews.shape = {vectorized_reviews.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3951093-c92c-49cd-abc2-d87183c3a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(processed=True):\n",
    "\n",
    "    X_proc = data_processed[\"text_processed\"]\n",
    "    X = data_processed[\"text\"]\n",
    "    y = data_processed[\"offensive\"]\n",
    "\n",
    "    pipeline_naive_bayes = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    MultinomialNB())\n",
    "\n",
    "    if processed:\n",
    "        model = pipeline_naive_bayes.fit(X_proc, y)\n",
    "\n",
    "    else:\n",
    "        model = pipeline_naive_bayes.fit(X, y)\n",
    "\n",
    "    print(f\"model trained, accuracy score is {round(model.score(X,y),2)}, , model with {processed=}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c6d0337-8b56-4960-9204-f6d1c0740179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained, accuracy score is 0.76, , model with processed=True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "edcebd0d-4fd0-42e2-a4d9-f49b7b6b77b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained, accuracy score is 0.76, , model with processed=True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model(processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed7b2935-52ec-425d-a12c-ff3b8ca8f2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained, accuracy score is 0.83, , model with processed=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model(processed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b92d9e-2696-4b63-b1a1-b8a5b43d186f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e9984a8c-06c7-4c9e-abb5-426d4630db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_baseline(X_pred: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Make a prediction using the latest trained model\n",
    "    \"\"\"\n",
    "    model = baseline_model(processed = False)\n",
    "\n",
    "    print(\"\\n⭐️ Use case: predict\")\n",
    "\n",
    "    X=[X_pred]\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    if y_pred[0] == 1: \n",
    "        print(f\"prediction done: your tweet is offensive, {y_pred[0]}\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee324ff5-8c31-46c8-bdb2-ceff59a0064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a tweet:  hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained, accuracy score is 0.83, , model with processed=False\n",
      "\n",
      "⭐️ Use case: predict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = str(input(\"Enter a tweet: \"))\n",
    "pred_baseline(X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "299dd4fd-6d21-4e7e-9482-cb8610501c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "035bd7d2-1efe-4f00-b665-d853a36b095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>offensive</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>1</td>\n",
       "      <td>dalits be lowlives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>gay people are a burden to our society</td>\n",
       "      <td>1</td>\n",
       "      <td>gay people be a burden to our society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>Arabs are not welcome</td>\n",
       "      <td>1</td>\n",
       "      <td>arabs be not welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>I'm not saying we should actually eliminate he...</td>\n",
       "      <td>1</td>\n",
       "      <td>im not say we should actually eliminate heebs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate_Speech_Classification_01</td>\n",
       "      <td>bananas are for black people</td>\n",
       "      <td>1</td>\n",
       "      <td>bananas be for black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169211</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>Almost everyone chose Long or Doki, WRL MVPs a...</td>\n",
       "      <td>0</td>\n",
       "      <td>almost everyone choose long or doki wrl mvps a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169212</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>You're never too old to get excited about gett...</td>\n",
       "      <td>0</td>\n",
       "      <td>youre never too old to get excite about get st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169213</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>(ASMR) Retro Massage Roleplay With A Rubber Pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>asmr retro massage roleplay with a rubber pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169214</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>@la_mcgillicuddy @storyteller1917 @patgagnon_7...</td>\n",
       "      <td>0</td>\n",
       "      <td>lamcgillicuddy storyteller patgagnon just avoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169215</th>\n",
       "      <td>Happy_tweets</td>\n",
       "      <td>@HelenTBracken Me too!! I dream of the peacefu...</td>\n",
       "      <td>0</td>\n",
       "      <td>helentbracken me too i dream of the peaceful l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169216 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               source  \\\n",
       "0       Hate_Speech_Classification_01   \n",
       "1       Hate_Speech_Classification_01   \n",
       "2       Hate_Speech_Classification_01   \n",
       "3       Hate_Speech_Classification_01   \n",
       "4       Hate_Speech_Classification_01   \n",
       "...                               ...   \n",
       "169211                   Happy_tweets   \n",
       "169212                   Happy_tweets   \n",
       "169213                   Happy_tweets   \n",
       "169214                   Happy_tweets   \n",
       "169215                   Happy_tweets   \n",
       "\n",
       "                                                     text  offensive  \\\n",
       "0                                     dalits are lowlives          1   \n",
       "1                  gay people are a burden to our society          1   \n",
       "2                                   Arabs are not welcome          1   \n",
       "3       I'm not saying we should actually eliminate he...          1   \n",
       "4                            bananas are for black people          1   \n",
       "...                                                   ...        ...   \n",
       "169211  Almost everyone chose Long or Doki, WRL MVPs a...          0   \n",
       "169212  You're never too old to get excited about gett...          0   \n",
       "169213  (ASMR) Retro Massage Roleplay With A Rubber Pa...          0   \n",
       "169214  @la_mcgillicuddy @storyteller1917 @patgagnon_7...          0   \n",
       "169215  @HelenTBracken Me too!! I dream of the peacefu...          0   \n",
       "\n",
       "                                           text_processed  \n",
       "0                                      dalits be lowlives  \n",
       "1                   gay people be a burden to our society  \n",
       "2                                    arabs be not welcome  \n",
       "3       im not say we should actually eliminate heebs ...  \n",
       "4                             bananas be for black people  \n",
       "...                                                   ...  \n",
       "169211  almost everyone choose long or doki wrl mvps a...  \n",
       "169212  youre never too old to get excite about get st...  \n",
       "169213  asmr retro massage roleplay with a rubber pape...  \n",
       "169214  lamcgillicuddy storyteller patgagnon just avoi...  \n",
       "169215  helentbracken me too i dream of the peaceful l...  \n",
       "\n",
       "[169216 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "82706370-e680-4c3f-81dd-e61edce52f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(processed=True):\n",
    "\n",
    "    if processed :\n",
    "        X = data_processed[\"text\"]\n",
    "        y = data_processed[\"offensive\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "    else :\n",
    "        X = data_processed[\"text_processed\"]\n",
    "        y = data_processed[\"offensive\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "\n",
    "    ### Let's tokenize the vocabulary\n",
    "    tk = Tokenizer()\n",
    "    tk.fit_on_texts(X_train)\n",
    "    vocab_size = len(tk.word_index)\n",
    "\n",
    "    # We apply the tokenization to the train and test set\n",
    "    X_train_token = tk.texts_to_sequences(X_train)\n",
    "    X_test_token = tk.texts_to_sequences(X_test)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "    X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')\n",
    "\n",
    "    ### Let's build the neural network now\n",
    "\n",
    "    # Size of your embedding space = size of the vector representing each word\n",
    "    embedding_size = 50\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(\n",
    "        input_dim=vocab_size+1, # size of the input, impacting the number of weights in the linear combinations of the neurons of the first layer\n",
    "        output_dim=embedding_size, # 100\n",
    "        mask_zero=True, # Built-in masking layer\n",
    "    ))\n",
    "\n",
    "    model.add(layers.LSTM(20, return_sequences=True, activation=\"tanh\"))\n",
    "    model.add(layers.LSTM(20, activation=\"tanh\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train_pad, y_train,\n",
    "            epochs=5,\n",
    "            batch_size=128,\n",
    "            callbacks=[es]\n",
    "            )\n",
    "\n",
    "    res = model.evaluate(X_test_pad, y_test)\n",
    "    print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%, model with {processed=}\"')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8266bf8-464b-49cc-a191-37c5e7a442f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 50)          8206650   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 20)          5680      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8215631 (31.34 MB)\n",
      "Trainable params: 8215631 (31.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "992/992 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8080WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "992/992 [==============================] - 470s 468ms/step - loss: 0.3790 - accuracy: 0.8080\n",
      "Epoch 2/5\n",
      "992/992 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.8561WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "992/992 [==============================] - 508s 513ms/step - loss: 0.3018 - accuracy: 0.8561\n",
      "Epoch 3/5\n",
      "992/992 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.8720WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "992/992 [==============================] - 474s 478ms/step - loss: 0.2767 - accuracy: 0.8720\n",
      "Epoch 4/5\n",
      "992/992 [==============================] - ETA: 0s - loss: 0.2589 - accuracy: 0.8813WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "992/992 [==============================] - 515s 519ms/step - loss: 0.2589 - accuracy: 0.8813\n",
      "Epoch 5/5\n",
      "992/992 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.8906WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "992/992 [==============================] - 551s 555ms/step - loss: 0.2427 - accuracy: 0.8906\n",
      "1322/1322 [==============================] - 140s 104ms/step - loss: 0.3155 - accuracy: 0.8532\n",
      "The accuracy evaluated on the test set is of 85.321%, model with processed=True\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x7f58b2637be0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model(processed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f2fa5-85cc-4a0b-91d8-e6056d2cdfdb",
   "metadata": {},
   "source": [
    "## ML for multilabelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21baf594-20c3-4a8a-9b35-d6fa68bd9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4fa41f-65f8-41e9-80ce-09e38fa954cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/mariannettrd/code/irismarechal1997/moder_ia/data/data_classif.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed6659c-c1e6-4189-8225-4fd46bb683e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'hate_speech_score', 'target_race', 'target_religion',\n",
       "       'target_origin', 'target_gender_women', 'target_gender_without_women',\n",
       "       'target_sexuality', 'target_age', 'target_disability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24feca2b-f12a-4d2b-93bb-3415f0504e94",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/pandas/core/frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5201\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5211\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5212\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5345\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop(columns=\"Unnamed: 0\", inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32727881-b4dc-4906-9379-c48719bd8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns =\"hate_speech_score\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dda4907-efc2-42b5-80d0-51fa981c678b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_race</th>\n",
       "      <th>target_religion</th>\n",
       "      <th>target_origin</th>\n",
       "      <th>target_gender_women</th>\n",
       "      <th>target_gender_without_women</th>\n",
       "      <th>target_sexuality</th>\n",
       "      <th>target_age</th>\n",
       "      <th>target_disability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135556 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  target_race  \\\n",
       "0       Yes indeed. She sort of reminds me of the elde...         True   \n",
       "1       The trans women reading this tweet right now i...        False   \n",
       "2       Question: These 4 broads who criticize America...        False   \n",
       "3       It is about time for all illegals to go back t...        False   \n",
       "4       For starters bend over the one in pink and kic...        False   \n",
       "...                                                   ...          ...   \n",
       "135551  عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...        False   \n",
       "135552  Millions of #Yemen-is participated in mass ral...         True   \n",
       "135553  @AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...        False   \n",
       "135554  Millions of #Yemen-is participated in mass ral...        False   \n",
       "135555  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...        False   \n",
       "\n",
       "        target_religion  target_origin  target_gender_women  \\\n",
       "0                 False          False                False   \n",
       "1                 False          False                False   \n",
       "2                 False           True                False   \n",
       "3                 False           True                False   \n",
       "4                 False          False                 True   \n",
       "...                 ...            ...                  ...   \n",
       "135551             True          False                False   \n",
       "135552             True          False                False   \n",
       "135553             True           True                False   \n",
       "135554             True          False                False   \n",
       "135555            False           True                False   \n",
       "\n",
       "        target_gender_without_women  target_sexuality  target_age  \\\n",
       "0                             False             False       False   \n",
       "1                              True             False       False   \n",
       "2                             False             False       False   \n",
       "3                             False             False       False   \n",
       "4                             False             False       False   \n",
       "...                             ...               ...         ...   \n",
       "135551                        False             False       False   \n",
       "135552                        False             False       False   \n",
       "135553                        False             False       False   \n",
       "135554                        False             False       False   \n",
       "135555                        False             False       False   \n",
       "\n",
       "        target_disability  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                   False  \n",
       "3                   False  \n",
       "4                   False  \n",
       "...                   ...  \n",
       "135551              False  \n",
       "135552              False  \n",
       "135553              False  \n",
       "135554              False  \n",
       "135555              False  \n",
       "\n",
       "[135556 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20da9f21-8cfd-443a-9188-0751e49fe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictrename = {'target_race': 'racism',\n",
    "              'target_religion': 'religion',\n",
    "              'target_origin': 'xenophobia',\n",
    "              'target_gender_women':'misogyny',\n",
    "              'target_gender_without_women':'transphobia',\n",
    "              'target_sexuality': 'homophobia',\n",
    "              'target_age': 'ageism',\n",
    "              'target_disability':'validism'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce10d2fc-4798-4d5d-a2d8-b1fb237e5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'target_race': 'racism',\n",
    "              'target_religion': 'religion',\n",
    "              'target_origin': 'xenophobia',\n",
    "              'target_gender_women':'misogyny',\n",
    "              'target_gender_without_women':'transphobia',\n",
    "              'target_sexuality': 'homophobia',\n",
    "              'target_age': 'ageism',\n",
    "              'target_disability':'validism'}, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76d6be37-3c61-48e6-8061-d50cdf75c07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>misogyny</th>\n",
       "      <th>transphobia</th>\n",
       "      <th>homophobia</th>\n",
       "      <th>ageism</th>\n",
       "      <th>validism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135556 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  racism  religion  \\\n",
       "0       Yes indeed. She sort of reminds me of the elde...    True     False   \n",
       "1       The trans women reading this tweet right now i...   False     False   \n",
       "2       Question: These 4 broads who criticize America...   False     False   \n",
       "3       It is about time for all illegals to go back t...   False     False   \n",
       "4       For starters bend over the one in pink and kic...   False     False   \n",
       "...                                                   ...     ...       ...   \n",
       "135551  عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...   False      True   \n",
       "135552  Millions of #Yemen-is participated in mass ral...    True      True   \n",
       "135553  @AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...   False      True   \n",
       "135554  Millions of #Yemen-is participated in mass ral...   False      True   \n",
       "135555  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...   False     False   \n",
       "\n",
       "        xenophobia  misogyny  transphobia  homophobia  ageism  validism  \n",
       "0            False     False        False       False   False     False  \n",
       "1            False     False         True       False   False     False  \n",
       "2             True     False        False       False   False     False  \n",
       "3             True     False        False       False   False     False  \n",
       "4            False      True        False       False   False     False  \n",
       "...            ...       ...          ...         ...     ...       ...  \n",
       "135551       False     False        False       False   False     False  \n",
       "135552       False     False        False       False   False     False  \n",
       "135553        True     False        False       False   False     False  \n",
       "135554       False     False        False       False   False     False  \n",
       "135555        True     False        False       False   False     False  \n",
       "\n",
       "[135556 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceb09dd5-b4cc-463e-a991-44492be9d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ['racism', 'religion', 'xenophobia', 'misogyny', 'transphobia', 'homophobia', 'ageism', 'validism']:\n",
    "    df[row] = df[row].replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "209d4b7f-d37b-4d51-b95e-369a996a210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>misogyny</th>\n",
       "      <th>transphobia</th>\n",
       "      <th>homophobia</th>\n",
       "      <th>ageism</th>\n",
       "      <th>validism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135556 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  racism  religion  \\\n",
       "0       Yes indeed. She sort of reminds me of the elde...       1         0   \n",
       "1       The trans women reading this tweet right now i...       0         0   \n",
       "2       Question: These 4 broads who criticize America...       0         0   \n",
       "3       It is about time for all illegals to go back t...       0         0   \n",
       "4       For starters bend over the one in pink and kic...       0         0   \n",
       "...                                                   ...     ...       ...   \n",
       "135551  عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...       0         1   \n",
       "135552  Millions of #Yemen-is participated in mass ral...       1         1   \n",
       "135553  @AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...       0         1   \n",
       "135554  Millions of #Yemen-is participated in mass ral...       0         1   \n",
       "135555  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...       0         0   \n",
       "\n",
       "        xenophobia  misogyny  transphobia  homophobia  ageism  validism  \n",
       "0                0         0            0           0       0         0  \n",
       "1                0         0            1           0       0         0  \n",
       "2                1         0            0           0       0         0  \n",
       "3                1         0            0           0       0         0  \n",
       "4                0         1            0           0       0         0  \n",
       "...            ...       ...          ...         ...     ...       ...  \n",
       "135551           0         0            0           0       0         0  \n",
       "135552           0         0            0           0       0         0  \n",
       "135553           1         0            0           0       0         0  \n",
       "135554           0         0            0           0       0         0  \n",
       "135555           1         0            0           0       0         0  \n",
       "\n",
       "[135556 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a655bcc3-ad87-45ca-9d5b-152782ea066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_table(data):\n",
    "    data = data.drop_duplicates() # Remove duplicates\n",
    "    data = data.dropna(subset=['offensive']) # Remove n.a. values in columns 'Label' => check column\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dedfaa82-c641-4525-a508-cb1ce7015963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning_table(data):\n",
    "    data = data.drop_duplicates() # Remove duplicates\n",
    "    data = data.dropna(subset=['text']) # Remove n.a. values in columns 'Label' => check column\n",
    "    return data\n",
    "\n",
    "# Note: no need to Scale the features, Encode features, Perform cyclical engineering\n",
    "\n",
    "def cleaning_text(sentence: str) -> str:\n",
    "\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "\n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    #remove words\n",
    "    removed = [\"user\", \"rt\"]\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in removed\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "\n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized)\n",
    "\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "543a2ec9-61d0-405a-9f06-08b69ecd9638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_processed = cleaning_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37837bf5-43ff-45cd-a96a-10f7471b7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed[\"text_processed\"] = data_processed[\"text\"].apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d55cb3f-df11-411c-8e62-afa641da45fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>misogyny</th>\n",
       "      <th>transphobia</th>\n",
       "      <th>homophobia</th>\n",
       "      <th>ageism</th>\n",
       "      <th>validism</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes indeed she sort of remind me of the elder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the trans women read this tweet right now be b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>question these broads who criticize america wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it be about time for all illegals to go back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>for starters bend over the one in pink and kic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135550</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abeshinzo realdonaldtrump shinzoabe 独裁者は行きますこれ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>عاجل سماحة السيدعبدالملكبدرالدينالحوثي نصره ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>millions of yemenis participate in mass rally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abeshinzo realdonaldtrump shinzoabe 独裁者は行きますこれ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>millions of yemenis participate in mass rally ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57716 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  racism  religion  \\\n",
       "0       Yes indeed. She sort of reminds me of the elde...       1         0   \n",
       "1       The trans women reading this tweet right now i...       0         0   \n",
       "2       Question: These 4 broads who criticize America...       0         0   \n",
       "3       It is about time for all illegals to go back t...       0         0   \n",
       "4       For starters bend over the one in pink and kic...       0         0   \n",
       "...                                                   ...     ...       ...   \n",
       "135550  @AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...       1         1   \n",
       "135551  عاجل سماحة #السيد_عبدالملك_بدرالدين_الحوثي  نص...       0         1   \n",
       "135552  Millions of #Yemen-is participated in mass ral...       1         1   \n",
       "135553  @AbeShinzo @realDonaldTrump @shinzoabe 独裁者は行きま...       0         1   \n",
       "135554  Millions of #Yemen-is participated in mass ral...       0         1   \n",
       "\n",
       "        xenophobia  misogyny  transphobia  homophobia  ageism  validism  \\\n",
       "0                0         0            0           0       0         0   \n",
       "1                0         0            1           0       0         0   \n",
       "2                1         0            0           0       0         0   \n",
       "3                1         0            0           0       0         0   \n",
       "4                0         1            0           0       0         0   \n",
       "...            ...       ...          ...         ...     ...       ...   \n",
       "135550           0         0            0           0       0         0   \n",
       "135551           0         0            0           0       0         0   \n",
       "135552           0         0            0           0       0         0   \n",
       "135553           1         0            0           0       0         0   \n",
       "135554           0         0            0           0       0         0   \n",
       "\n",
       "                                           text_processed  \n",
       "0       yes indeed she sort of remind me of the elder ...  \n",
       "1       the trans women read this tweet right now be b...  \n",
       "2       question these broads who criticize america wh...  \n",
       "3       it be about time for all illegals to go back t...  \n",
       "4       for starters bend over the one in pink and kic...  \n",
       "...                                                   ...  \n",
       "135550  abeshinzo realdonaldtrump shinzoabe 独裁者は行きますこれ...  \n",
       "135551  عاجل سماحة السيدعبدالملكبدرالدينالحوثي نصره ال...  \n",
       "135552  millions of yemenis participate in mass rally ...  \n",
       "135553  abeshinzo realdonaldtrump shinzoabe 独裁者は行きますこれ...  \n",
       "135554  millions of yemenis participate in mass rally ...  \n",
       "\n",
       "[57716 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "298e2215-0b2d-4d65-9f89-326fee6346e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dacd0f32-ba58-4866-858e-a7d277817fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "\n",
    "ModelsPerformance = {}\n",
    "\n",
    "def metricsReport(modelName, test_labels, predictions):\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    macro_precision = precision_score(test_labels, predictions, average='macro')\n",
    "    macro_recall = recall_score(test_labels, predictions, average='macro')\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "\n",
    "    micro_precision = precision_score(test_labels, predictions, average='micro')\n",
    "    micro_recall = recall_score(test_labels, predictions, average='micro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    print(\"------\" + modelName + \" Model Metrics-----\")\n",
    "    print(\"Accuracy: {:.4f}\\nHamming Loss: {:.4f}\\nPrecision:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nRecall:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nF1-measure:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\"\\\n",
    "          .format(accuracy, hamLoss, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))\n",
    "    ModelsPerformance[modelName] = micro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3cd172d7-7d27-4799-b5a8-8996614abcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_processed[\"text\"]\n",
    "y = data_processed.drop(labels=[\"text_processed\", \"text\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5b0cab6-3e75-4d73-aa01-4195385181e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------SVC Sq. Hinge Loss Model Metrics-----\n",
      "Accuracy: 0.3629\n",
      "Hamming Loss: 0.1214\n",
      "Precision:\n",
      "  - Macro: 0.6161\n",
      "  - Micro: 0.6725\n",
      "Recall:\n",
      "  - Macro: 0.4714\n",
      "  - Micro: 0.5517\n",
      "F1-measure:\n",
      "  - Macro: 0.5259\n",
      "  - Micro: 0.6061\n"
     ]
    }
   ],
   "source": [
    "# Pipeline vectorizer + LinearSVC\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(), \n",
    "    OneVsRestClassifier(LinearSVC(), n_jobs=-1))\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "svmPreds = pipeline.predict(X_test)\n",
    "metricsReport(\"SVC Sq. Hinge Loss\", y_test, svmPreds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f591350-e707-4ac0-9b77-2ccf9daa2061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Multinomial NB Model Metrics-----\n",
      "Accuracy: 0.0949\n",
      "Hamming Loss: 0.1563\n",
      "Precision:\n",
      "  - Macro: 0.5451\n",
      "  - Micro: 0.7547\n",
      "Recall:\n",
      "  - Macro: 0.0801\n",
      "  - Micro: 0.1140\n",
      "F1-measure:\n",
      "  - Macro: 0.1362\n",
      "  - Micro: 0.1981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(), \n",
    "    OneVsRestClassifier(MultinomialNB()))\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "svmPreds = pipeline.predict(X_test)\n",
    "metricsReport(\"Multinomial NB\", y_test, svmPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "922366f4-9abb-4b7b-90a8-3f6cdd2015ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "#import keras\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f651d1f8-d55d-45fa-ab08-1dfb1d46fdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 50)          2178550   \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, None, 20)          4320      \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 20)                2520      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 168       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2185558 (8.34 MB)\n",
      "Trainable params: 2185558 (8.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.3272WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 120s 318ms/step - loss: 0.4434 - accuracy: 0.3272\n",
      "Epoch 2/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.3299WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 108s 320ms/step - loss: 0.4190 - accuracy: 0.3299\n",
      "Epoch 3/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.3953WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 94s 278ms/step - loss: 0.3963 - accuracy: 0.3953\n",
      "Epoch 4/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.4866WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 94s 278ms/step - loss: 0.3518 - accuracy: 0.4866\n",
      "Epoch 5/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.5382WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 61s 179ms/step - loss: 0.3268 - accuracy: 0.5382\n",
      "451/451 [==============================] - 11s 21ms/step - loss: 0.3201 - accuracy: 0.5291\n",
      "The accuracy evaluated on the test set is of 52.907%\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing data\n",
    "X = data_processed[\"text\"]\n",
    "y = data_processed.drop(labels=[\"text_processed\", \"text\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "\n",
    "### Let's tokenize the vocabulary\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(X_train)\n",
    "vocab_size = len(tk.word_index)\n",
    "\n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tk.texts_to_sequences(X_train)\n",
    "X_test_token = tk.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')\n",
    "\n",
    "# Size of your embedding space = size of the vector representing each word\n",
    "embedding_size = 50\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(\n",
    "    input_dim=vocab_size+1, # size of the input, impacting the number of weights in the linear combinations of the neurons of the first layer\n",
    "    output_dim=embedding_size, # 100\n",
    "    mask_zero=True, # Built-in masking layer\n",
    "))\n",
    "\n",
    "model.add(layers.GRU(20, return_sequences=True, activation=\"tanh\"))\n",
    "model.add(layers.GRU(20, activation=\"tanh\"))\n",
    "model.add(layers.Dense(8, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train,\n",
    "        epochs=5,\n",
    "        batch_size=128,\n",
    "        callbacks=[es]\n",
    "        )\n",
    "\n",
    "res = model.evaluate(X_test_pad, y_test)\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "089bc401-dd0d-415f-8926-29d2308e9ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, None, 50)          2178550   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, None, 32)          4832      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, None, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               53200     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 808       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2237390 (8.53 MB)\n",
      "Trainable params: 2237390 (8.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.6492WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 43s 125ms/step - loss: 0.2588 - accuracy: 0.6492\n",
      "Epoch 2/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.6592WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 46s 137ms/step - loss: 0.2530 - accuracy: 0.6592\n",
      "Epoch 3/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.6672WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 52s 154ms/step - loss: 0.2481 - accuracy: 0.6672\n",
      "Epoch 4/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.6746WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 50s 149ms/step - loss: 0.2429 - accuracy: 0.6746\n",
      "Epoch 5/5\n",
      "339/339 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.6825WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "339/339 [==============================] - 60s 177ms/step - loss: 0.2381 - accuracy: 0.6825\n",
      "451/451 [==============================] - 12s 26ms/step - loss: 0.2936 - accuracy: 0.5753\n",
      "The accuracy evaluated on the test set is of 57.530%\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "# Split into training and testing data\n",
    "X = data_processed[\"text\"]\n",
    "y = data_processed.drop(labels=[\"text_processed\", \"text\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "\n",
    "### Let's tokenize the vocabulary\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(X_train)\n",
    "vocab_size = len(tk.word_index)\n",
    "\n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tk.texts_to_sequences(X_train)\n",
    "X_test_token = tk.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')\n",
    "\n",
    "# Size of your embedding space = size of the vector representing each word\n",
    "embedding_size = 50\n",
    "\n",
    "# create the model\n",
    "max_review_length = 600\n",
    "\n",
    "embedding_vector_length = 32\n",
    "cnn_model = Sequential()\n",
    "\n",
    "\n",
    "cnn_model.add(Embedding(input_dim=vocab_size+1, output_dim=embedding_size))   \n",
    "cnn_model.add(layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "cnn_model.add(layers.MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(layers.LSTM(100))\n",
    "cnn_model.add(layers.Dense(8, activation='sigmoid'))\n",
    "\n",
    "# Students will be ending their code here\n",
    "\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(cnn_model.summary())\n",
    "\n",
    "# Change the number of epochs and the batch size depending on the RAM Size\n",
    "\n",
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "history_c =model.fit(X_train_pad, y_train,\n",
    "        epochs=5,\n",
    "        batch_size=128,\n",
    "        callbacks=[es]\n",
    "        )\n",
    "res = model.evaluate(X_test_pad, y_test)\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce304ef3-321a-4e62-ae56-d76c5f611699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
