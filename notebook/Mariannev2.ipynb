{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bfe2301",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hateXplain \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/mariannettrd/code/irismarechal1997/moder_ia/raw_data/230911_HateXplain.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m hateXplain_inversed \u001b[38;5;241m=\u001b[39m hateXplain\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m      5\u001b[0m hateXplain\u001b[38;5;241m=\u001b[39mhateXplain_inversed\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "hateXplain = pd.read_json(\"/home/mariannettrd/code/irismarechal1997/moder_ia/raw_data/230911_HateXplain.json\")\n",
    "\n",
    "hateXplain_inversed = hateXplain.transpose()\n",
    "\n",
    "hateXplain=hateXplain_inversed\n",
    "\n",
    "\n",
    "hateXplain[\"source\"]=\"230911_HateXplain\" # add source of the doc\n",
    "\n",
    "\n",
    "hateXplain = hateXplain[[\"post_tokens\", \"annotators\", \"source\"]].copy()\n",
    "\n",
    "hateXplain.reset_index(inplace=True, drop=True)\n",
    "\n",
    "hateXplain[\"offensive\"]=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e02ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hateXplain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56c156",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for i in range(0,len(hateXplain)): \n",
    "#     hateXplain.iloc[i,-1]= hateXplain.iloc[i,1][0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740b5df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hateXplain[\"offensive\"]=hateXplain[\"annotators\"].apply(lambda x:x[0][\"label\"]).apply(lambda x:0 if x ==\"normal\" else 1)\n",
    "hateXplain[\"offensive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916917cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hateXplain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f2fa5-85cc-4a0b-91d8-e6056d2cdfdb",
   "metadata": {},
   "source": [
    "## ML for multilabelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21baf594-20c3-4a8a-9b35-d6fa68bd9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4fa41f-65f8-41e9-80ce-09e38fa954cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/mariannettrd/code/irismarechal1997/moder_ia/data/data_classif.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed6659c-c1e6-4189-8225-4fd46bb683e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'hate_speech_score', 'target_race',\n",
       "       'target_religion', 'target_origin', 'target_gender_women',\n",
       "       'target_gender_without_women', 'target_sexuality', 'target_age',\n",
       "       'target_disability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24feca2b-f12a-4d2b-93bb-3415f0504e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"Unnamed: 0\", inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32727881-b4dc-4906-9379-c48719bd8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns =\"hate_speech_score\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dda4907-efc2-42b5-80d0-51fa981c678b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_race</th>\n",
       "      <th>target_religion</th>\n",
       "      <th>target_origin</th>\n",
       "      <th>target_gender_women</th>\n",
       "      <th>target_gender_without_women</th>\n",
       "      <th>target_sexuality</th>\n",
       "      <th>target_age</th>\n",
       "      <th>target_disability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© #Ø§Ù„Ø³ÙŠØ¯_Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ_Ø¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†_Ø§Ù„Ø­ÙˆØ«ÙŠ  Ù†Øµ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>Ù„Ø§ ØªØªØ´Ù…Øª Ø§Ù„Ø±Ø¬Ø§Ù„ Ù…Ø³ÙƒÙŠÙ† ÙŠØ¹Ø§Ù†ÙŠ ÙƒØ³ Ø§Ù…Ù‡ ğŸ˜‚. ÙŠÙ‚ÙˆÙ„ ÙŠØ§Ù„...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135556 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  target_race  \\\n",
       "0       Yes indeed. She sort of reminds me of the elde...         True   \n",
       "1       The trans women reading this tweet right now i...        False   \n",
       "2       Question: These 4 broads who criticize America...        False   \n",
       "3       It is about time for all illegals to go back t...        False   \n",
       "4       For starters bend over the one in pink and kic...        False   \n",
       "...                                                   ...          ...   \n",
       "135551  Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© #Ø§Ù„Ø³ÙŠØ¯_Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ_Ø¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†_Ø§Ù„Ø­ÙˆØ«ÙŠ  Ù†Øµ...        False   \n",
       "135552  Millions of #Yemen-is participated in mass ral...         True   \n",
       "135553  @AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...        False   \n",
       "135554  Millions of #Yemen-is participated in mass ral...        False   \n",
       "135555  Ù„Ø§ ØªØªØ´Ù…Øª Ø§Ù„Ø±Ø¬Ø§Ù„ Ù…Ø³ÙƒÙŠÙ† ÙŠØ¹Ø§Ù†ÙŠ ÙƒØ³ Ø§Ù…Ù‡ ğŸ˜‚. ÙŠÙ‚ÙˆÙ„ ÙŠØ§Ù„...        False   \n",
       "\n",
       "        target_religion  target_origin  target_gender_women  \\\n",
       "0                 False          False                False   \n",
       "1                 False          False                False   \n",
       "2                 False           True                False   \n",
       "3                 False           True                False   \n",
       "4                 False          False                 True   \n",
       "...                 ...            ...                  ...   \n",
       "135551             True          False                False   \n",
       "135552             True          False                False   \n",
       "135553             True           True                False   \n",
       "135554             True          False                False   \n",
       "135555            False           True                False   \n",
       "\n",
       "        target_gender_without_women  target_sexuality  target_age  \\\n",
       "0                             False             False       False   \n",
       "1                              True             False       False   \n",
       "2                             False             False       False   \n",
       "3                             False             False       False   \n",
       "4                             False             False       False   \n",
       "...                             ...               ...         ...   \n",
       "135551                        False             False       False   \n",
       "135552                        False             False       False   \n",
       "135553                        False             False       False   \n",
       "135554                        False             False       False   \n",
       "135555                        False             False       False   \n",
       "\n",
       "        target_disability  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                   False  \n",
       "3                   False  \n",
       "4                   False  \n",
       "...                   ...  \n",
       "135551              False  \n",
       "135552              False  \n",
       "135553              False  \n",
       "135554              False  \n",
       "135555              False  \n",
       "\n",
       "[135556 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20da9f21-8cfd-443a-9188-0751e49fe9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictrename = {'target_race': 'racism',\n",
    "              'target_religion': 'religion',\n",
    "              'target_origin': 'xenophobia',\n",
    "              'target_gender_women':'misogyny',\n",
    "              'target_gender_without_women':'transphobia',\n",
    "              'target_sexuality': 'homophobia',\n",
    "              'target_age': 'ageism',\n",
    "              'target_disability':'validism'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce10d2fc-4798-4d5d-a2d8-b1fb237e5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'target_race': 'racism',\n",
    "              'target_religion': 'religion',\n",
    "              'target_origin': 'xenophobia',\n",
    "              'target_gender_women':'misogyny',\n",
    "              'target_gender_without_women':'transphobia',\n",
    "              'target_sexuality': 'homophobia',\n",
    "              'target_age': 'ageism',\n",
    "              'target_disability':'validism'}, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76d6be37-3c61-48e6-8061-d50cdf75c07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>misogyny</th>\n",
       "      <th>transphobia</th>\n",
       "      <th>homophobia</th>\n",
       "      <th>ageism</th>\n",
       "      <th>validism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© #Ø§Ù„Ø³ÙŠØ¯_Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ_Ø¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†_Ø§Ù„Ø­ÙˆØ«ÙŠ  Ù†Øµ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>Ù„Ø§ ØªØªØ´Ù…Øª Ø§Ù„Ø±Ø¬Ø§Ù„ Ù…Ø³ÙƒÙŠÙ† ÙŠØ¹Ø§Ù†ÙŠ ÙƒØ³ Ø§Ù…Ù‡ ğŸ˜‚. ÙŠÙ‚ÙˆÙ„ ÙŠØ§Ù„...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135556 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  racism  religion  \\\n",
       "0       Yes indeed. She sort of reminds me of the elde...    True     False   \n",
       "1       The trans women reading this tweet right now i...   False     False   \n",
       "2       Question: These 4 broads who criticize America...   False     False   \n",
       "3       It is about time for all illegals to go back t...   False     False   \n",
       "4       For starters bend over the one in pink and kic...   False     False   \n",
       "...                                                   ...     ...       ...   \n",
       "135551  Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© #Ø§Ù„Ø³ÙŠØ¯_Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ_Ø¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†_Ø§Ù„Ø­ÙˆØ«ÙŠ  Ù†Øµ...   False      True   \n",
       "135552  Millions of #Yemen-is participated in mass ral...    True      True   \n",
       "135553  @AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...   False      True   \n",
       "135554  Millions of #Yemen-is participated in mass ral...   False      True   \n",
       "135555  Ù„Ø§ ØªØªØ´Ù…Øª Ø§Ù„Ø±Ø¬Ø§Ù„ Ù…Ø³ÙƒÙŠÙ† ÙŠØ¹Ø§Ù†ÙŠ ÙƒØ³ Ø§Ù…Ù‡ ğŸ˜‚. ÙŠÙ‚ÙˆÙ„ ÙŠØ§Ù„...   False     False   \n",
       "\n",
       "        xenophobia  misogyny  transphobia  homophobia  ageism  validism  \n",
       "0            False     False        False       False   False     False  \n",
       "1            False     False         True       False   False     False  \n",
       "2             True     False        False       False   False     False  \n",
       "3             True     False        False       False   False     False  \n",
       "4            False      True        False       False   False     False  \n",
       "...            ...       ...          ...         ...     ...       ...  \n",
       "135551       False     False        False       False   False     False  \n",
       "135552       False     False        False       False   False     False  \n",
       "135553        True     False        False       False   False     False  \n",
       "135554       False     False        False       False   False     False  \n",
       "135555        True     False        False       False   False     False  \n",
       "\n",
       "[135556 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb09dd5-b4cc-463e-a991-44492be9d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ['racism', 'religion', 'xenophobia', 'misogyny', 'transphobia', 'homophobia', 'ageism', 'validism']:\n",
    "    df[row] = df[row].replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "209d4b7f-d37b-4d51-b95e-369a996a210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>misogyny</th>\n",
       "      <th>transphobia</th>\n",
       "      <th>homophobia</th>\n",
       "      <th>ageism</th>\n",
       "      <th>validism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© #Ø§Ù„Ø³ÙŠØ¯_Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ_Ø¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†_Ø§Ù„Ø­ÙˆØ«ÙŠ  Ù†Øµ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>Ù„Ø§ ØªØªØ´Ù…Øª Ø§Ù„Ø±Ø¬Ø§Ù„ Ù…Ø³ÙƒÙŠÙ† ÙŠØ¹Ø§Ù†ÙŠ ÙƒØ³ Ø§Ù…Ù‡ ğŸ˜‚. ÙŠÙ‚ÙˆÙ„ ÙŠØ§Ù„...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135556 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  racism  religion  \\\n",
       "0       Yes indeed. She sort of reminds me of the elde...       1         0   \n",
       "1       The trans women reading this tweet right now i...       0         0   \n",
       "2       Question: These 4 broads who criticize America...       0         0   \n",
       "3       It is about time for all illegals to go back t...       0         0   \n",
       "4       For starters bend over the one in pink and kic...       0         0   \n",
       "...                                                   ...     ...       ...   \n",
       "135551  Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© #Ø§Ù„Ø³ÙŠØ¯_Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ_Ø¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†_Ø§Ù„Ø­ÙˆØ«ÙŠ  Ù†Øµ...       0         1   \n",
       "135552  Millions of #Yemen-is participated in mass ral...       1         1   \n",
       "135553  @AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...       0         1   \n",
       "135554  Millions of #Yemen-is participated in mass ral...       0         1   \n",
       "135555  Ù„Ø§ ØªØªØ´Ù…Øª Ø§Ù„Ø±Ø¬Ø§Ù„ Ù…Ø³ÙƒÙŠÙ† ÙŠØ¹Ø§Ù†ÙŠ ÙƒØ³ Ø§Ù…Ù‡ ğŸ˜‚. ÙŠÙ‚ÙˆÙ„ ÙŠØ§Ù„...       0         0   \n",
       "\n",
       "        xenophobia  misogyny  transphobia  homophobia  ageism  validism  \n",
       "0                0         0            0           0       0         0  \n",
       "1                0         0            1           0       0         0  \n",
       "2                1         0            0           0       0         0  \n",
       "3                1         0            0           0       0         0  \n",
       "4                0         1            0           0       0         0  \n",
       "...            ...       ...          ...         ...     ...       ...  \n",
       "135551           0         0            0           0       0         0  \n",
       "135552           0         0            0           0       0         0  \n",
       "135553           1         0            0           0       0         0  \n",
       "135554           0         0            0           0       0         0  \n",
       "135555           1         0            0           0       0         0  \n",
       "\n",
       "[135556 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a655bcc3-ad87-45ca-9d5b-152782ea066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_table(data):\n",
    "    data = data.drop_duplicates() # Remove duplicates\n",
    "    data = data.dropna(subset=['offensive']) # Remove n.a. values in columns 'Label' => check column\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dedfaa82-c641-4525-a508-cb1ce7015963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning_table(data):\n",
    "    data = data.drop_duplicates() # Remove duplicates\n",
    "    data = data.dropna(subset=['text']) # Remove n.a. values in columns 'Label' => check column\n",
    "    return data\n",
    "\n",
    "# Note: no need to Scale the features, Encode features, Perform cyclical engineering\n",
    "\n",
    "def cleaning_text(sentence: str) -> str:\n",
    "\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "\n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    #remove words\n",
    "    removed = [\"user\", \"rt\"]\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in removed\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "\n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized)\n",
    "\n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "543a2ec9-61d0-405a-9f06-08b69ecd9638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_processed = cleaning_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37837bf5-43ff-45cd-a96a-10f7471b7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed[\"text_processed\"] = data_processed[\"text\"].apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d55cb3f-df11-411c-8e62-afa641da45fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>misogyny</th>\n",
       "      <th>transphobia</th>\n",
       "      <th>homophobia</th>\n",
       "      <th>ageism</th>\n",
       "      <th>validism</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes indeed she sort of remind me of the elder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the trans women read this tweet right now be b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>question these broads who criticize america wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it be about time for all illegals to go back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>for starters bend over the one in pink and kic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135550</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abeshinzo realdonaldtrump shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾ã™ã“ã‚Œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© #Ø§Ù„Ø³ÙŠØ¯_Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ_Ø¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†_Ø§Ù„Ø­ÙˆØ«ÙŠ  Ù†Øµ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© Ø§Ù„Ø³ÙŠØ¯Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„ÙƒØ¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†Ø§Ù„Ø­ÙˆØ«ÙŠ Ù†ØµØ±Ù‡ Ø§Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>millions of yemenis participate in mass rally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>@AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abeshinzo realdonaldtrump shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾ã™ã“ã‚Œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>Millions of #Yemen-is participated in mass ral...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>millions of yemenis participate in mass rally ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57716 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  racism  religion  \\\n",
       "0       Yes indeed. She sort of reminds me of the elde...       1         0   \n",
       "1       The trans women reading this tweet right now i...       0         0   \n",
       "2       Question: These 4 broads who criticize America...       0         0   \n",
       "3       It is about time for all illegals to go back t...       0         0   \n",
       "4       For starters bend over the one in pink and kic...       0         0   \n",
       "...                                                   ...     ...       ...   \n",
       "135550  @AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...       1         1   \n",
       "135551  Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© #Ø§Ù„Ø³ÙŠØ¯_Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ_Ø¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†_Ø§Ù„Ø­ÙˆØ«ÙŠ  Ù†Øµ...       0         1   \n",
       "135552  Millions of #Yemen-is participated in mass ral...       1         1   \n",
       "135553  @AbeShinzo @realDonaldTrump @shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾...       0         1   \n",
       "135554  Millions of #Yemen-is participated in mass ral...       0         1   \n",
       "\n",
       "        xenophobia  misogyny  transphobia  homophobia  ageism  validism  \\\n",
       "0                0         0            0           0       0         0   \n",
       "1                0         0            1           0       0         0   \n",
       "2                1         0            0           0       0         0   \n",
       "3                1         0            0           0       0         0   \n",
       "4                0         1            0           0       0         0   \n",
       "...            ...       ...          ...         ...     ...       ...   \n",
       "135550           0         0            0           0       0         0   \n",
       "135551           0         0            0           0       0         0   \n",
       "135552           0         0            0           0       0         0   \n",
       "135553           1         0            0           0       0         0   \n",
       "135554           0         0            0           0       0         0   \n",
       "\n",
       "                                           text_processed  \n",
       "0       yes indeed she sort of remind me of the elder ...  \n",
       "1       the trans women read this tweet right now be b...  \n",
       "2       question these broads who criticize america wh...  \n",
       "3       it be about time for all illegals to go back t...  \n",
       "4       for starters bend over the one in pink and kic...  \n",
       "...                                                   ...  \n",
       "135550  abeshinzo realdonaldtrump shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾ã™ã“ã‚Œ...  \n",
       "135551  Ø¹Ø§Ø¬Ù„ Ø³Ù…Ø§Ø­Ø© Ø§Ù„Ø³ÙŠØ¯Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„ÙƒØ¨Ø¯Ø±Ø§Ù„Ø¯ÙŠÙ†Ø§Ù„Ø­ÙˆØ«ÙŠ Ù†ØµØ±Ù‡ Ø§Ù„...  \n",
       "135552  millions of yemenis participate in mass rally ...  \n",
       "135553  abeshinzo realdonaldtrump shinzoabe ç‹¬è£è€…ã¯è¡Œãã¾ã™ã“ã‚Œ...  \n",
       "135554  millions of yemenis participate in mass rally ...  \n",
       "\n",
       "[57716 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "298e2215-0b2d-4d65-9f89-326fee6346e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dacd0f32-ba58-4866-858e-a7d277817fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "\n",
    "ModelsPerformance = {}\n",
    "\n",
    "def metricsReport(modelName, test_labels, predictions):\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    macro_precision = precision_score(test_labels, predictions, average='macro')\n",
    "    macro_recall = recall_score(test_labels, predictions, average='macro')\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "\n",
    "    micro_precision = precision_score(test_labels, predictions, average='micro')\n",
    "    micro_recall = recall_score(test_labels, predictions, average='micro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    print(\"------\" + modelName + \" Model Metrics-----\")\n",
    "    print(\"Accuracy: {:.4f}\\nHamming Loss: {:.4f}\\nPrecision:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nRecall:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nF1-measure:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\"\\\n",
    "          .format(accuracy, hamLoss, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))\n",
    "    ModelsPerformance[modelName] = micro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cd172d7-7d27-4799-b5a8-8996614abcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_processed[\"text\"]\n",
    "y = data_processed.drop(labels=[\"text_processed\", \"text\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5b0cab6-3e75-4d73-aa01-4195385181e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/mariannettrd/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------SVC Sq. Hinge Loss Model Metrics-----\n",
      "Accuracy: 0.3629\n",
      "Hamming Loss: 0.1214\n",
      "Precision:\n",
      "  - Macro: 0.6160\n",
      "  - Micro: 0.6725\n",
      "Recall:\n",
      "  - Macro: 0.4714\n",
      "  - Micro: 0.5517\n",
      "F1-measure:\n",
      "  - Macro: 0.5258\n",
      "  - Micro: 0.6061\n"
     ]
    }
   ],
   "source": [
    "# Pipeline vectorizer + LinearSVC\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(), \n",
    "    OneVsRestClassifier(LinearSVC(), n_jobs=-1))\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "svmPreds = pipeline.predict(X_test)\n",
    "metricsReport(\"SVC Sq. Hinge Loss\", y_test, svmPreds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f591350-e707-4ac0-9b77-2ccf9daa2061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Multinomial NB Model Metrics-----\n",
      "Accuracy: 0.0949\n",
      "Hamming Loss: 0.1563\n",
      "Precision:\n",
      "  - Macro: 0.5451\n",
      "  - Micro: 0.7547\n",
      "Recall:\n",
      "  - Macro: 0.0801\n",
      "  - Micro: 0.1140\n",
      "F1-measure:\n",
      "  - Macro: 0.1362\n",
      "  - Micro: 0.1981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(), \n",
    "    OneVsRestClassifier(MultinomialNB()))\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "svmPreds = pipeline.predict(X_test)\n",
    "metricsReport(\"Multinomial NB\", y_test, svmPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "922366f4-9abb-4b7b-90a8-3f6cdd2015ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 12:19:17.569011: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-18 12:19:17.600921: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-18 12:19:17.601672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-18 12:19:18.420610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "#import keras\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651d1f8-d55d-45fa-ab08-1dfb1d46fdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 50)          2178550   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, None, 20)          4320      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 20)                2520      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 168       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2185558 (8.34 MB)\n",
      "Trainable params: 2185558 (8.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "122/339 [=========>....................] - ETA: 27s - loss: 0.4720 - accuracy: 0.2288"
     ]
    }
   ],
   "source": [
    "# Split into training and testing data\n",
    "X = data_processed[\"text\"]\n",
    "y = data_processed.drop(labels=[\"text_processed\", \"text\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "\n",
    "### Let's tokenize the vocabulary\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(X_train)\n",
    "vocab_size = len(tk.word_index)\n",
    "\n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tk.texts_to_sequences(X_train)\n",
    "X_test_token = tk.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')\n",
    "\n",
    "# Size of your embedding space = size of the vector representing each word\n",
    "embedding_size = 50\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(\n",
    "    input_dim=vocab_size+1, # size of the input, impacting the number of weights in the linear combinations of the neurons of the first layer\n",
    "    output_dim=embedding_size, # 100\n",
    "    mask_zero=True, # Built-in masking layer\n",
    "))\n",
    "\n",
    "model.add(layers.GRU(20, return_sequences=True, activation=\"tanh\"))\n",
    "model.add(layers.GRU(20, activation=\"tanh\"))\n",
    "model.add(layers.Dense(8, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_pad, y_train,\n",
    "        epochs=5,\n",
    "        batch_size=128,\n",
    "        callbacks=[es]\n",
    "        )\n",
    "\n",
    "res = model.evaluate(X_test_pad, y_test)\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089bc401-dd0d-415f-8926-29d2308e9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "# Split into training and testing data\n",
    "X = data_processed[\"text\"]\n",
    "y = data_processed.drop(labels=[\"text_processed\", \"text\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "\n",
    "### Let's tokenize the vocabulary\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(X_train)\n",
    "vocab_size = len(tk.word_index)\n",
    "\n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tk.texts_to_sequences(X_train)\n",
    "X_test_token = tk.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')\n",
    "\n",
    "# Size of your embedding space = size of the vector representing each word\n",
    "embedding_size = 50\n",
    "\n",
    "# create the model\n",
    "max_review_length = 600\n",
    "\n",
    "embedding_vector_length = 32\n",
    "cnn_model = Sequential()\n",
    "\n",
    "\n",
    "cnn_model.add(Embedding(input_dim=vocab_size+1, output_dim=embedding_size))   \n",
    "cnn_model.add(layers.Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "cnn_model.add(layers.MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(layers.LSTM(100))\n",
    "cnn_model.add(layers.Dense(8, activation='sigmoid'))\n",
    "\n",
    "# Students will be ending their code here\n",
    "\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(cnn_model.summary())\n",
    "\n",
    "# Change the number of epochs and the batch size depending on the RAM Size\n",
    "\n",
    "es = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "history_c =model.fit(X_train_pad, y_train,\n",
    "        epochs=5,\n",
    "        batch_size=128,\n",
    "        callbacks=[es]\n",
    "        )\n",
    "res = model.evaluate(X_test_pad, y_test)\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61042bbd-d028-4060-bc9f-9e5fd356db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X_train_pad)\n",
    "test_predictions = model.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282b393-9e52-43c4-8a3a-56add8962dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89edf2-dbbe-4f80-ab97-d3ba35a920f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = np.argmax(train_predictions, axis=1)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb591fc-5ba4-442e-ae1b-33217df50841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce304ef3-321a-4e62-ae56-d76c5f611699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "\n",
    "treshold = 0.5\n",
    "\n",
    "train_hamming_loss = hamming_loss(X_train_pad, (train_predictions > threshold))\n",
    "test_hamming_loss = hamming_loss(X_test_pad, (test_predictions > threshold))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a185b8-8102-49a2-9597-2f7dbd77bc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c3ebb5-cca8-4fa5-baf3-00b7a85a63ae",
   "metadata": {},
   "source": [
    "## One model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d31c1-31b5-4b92-b305-f6147f8d12ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
