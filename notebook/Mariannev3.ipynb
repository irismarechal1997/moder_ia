{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1fe64c73-266a-41b2-b5d2-f18e3733c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langdetect import detect\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import BertConfig, AutoTokenizer, TFBertModel, BertTokenizer, TFBertForSequenceClassification, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import hamming_loss\n",
    "from utils.registry import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from utils.data_preproc import cleaning_text\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c2a5ad30-0a02-42cc-bb0a-c6bf0048b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── generate_tweet_iris.ipynb\n",
      "├── haha.txt\n",
      "├── __init__.py\n",
      "├── Iris_2.ipynb\n",
      "├── iris_3-Copy1.ipynb\n",
      "├── iris_3.ipynb\n",
      "├── iris_4.ipynb\n",
      "├── Iris Notebook.ipynb\n",
      "├── iris_streamlit.ipynb\n",
      "├── irisv5.ipynb\n",
      "├── LSTM_DL.ipynb\n",
      "├── Marianne.ipynb\n",
      "├── Mariannev2.ipynb\n",
      "├── Mariannev2.ipynb:Zone.Identifier\n",
      "├── Mariannev3.ipynb\n",
      "├── \u001b[01;34m__pycache__\u001b[0m\n",
      "│   └── __init__.cpython-310.pyc\n",
      "├── test-bert.ipynb\n",
      "└── test_lua.ipynb\n",
      "\n",
      "1 directory, 18 files\n"
     ]
    }
   ],
   "source": [
    "! tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b28f3480-621b-4fb0-a8a7-652038d6ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/labelling_dataset_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c2b25131-ed73-413e-bd2b-98d7d16b4f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>misogyny</th>\n",
       "      <th>transphobia</th>\n",
       "      <th>homophobia</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes indeed she sort of remind me of the elder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>the trans women read this tweet right now be b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>question these broads who criticize america wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it be about time for all illegals to go back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>for starters bend over the one in pink and kic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  racism  religion  \\\n",
       "0  Yes indeed. She sort of reminds me of the elde...       1         0   \n",
       "1  The trans women reading this tweet right now i...       0         0   \n",
       "2  Question: These 4 broads who criticize America...       0         0   \n",
       "3  It is about time for all illegals to go back t...       0         0   \n",
       "4  For starters bend over the one in pink and kic...       0         0   \n",
       "\n",
       "   xenophobia  misogyny  transphobia  homophobia  \\\n",
       "0           0         0            0           0   \n",
       "1           0         0            1           0   \n",
       "2           1         0            0           0   \n",
       "3           1         0            0           0   \n",
       "4           0         1            0           0   \n",
       "\n",
       "                                      text_processed  \n",
       "0  yes indeed she sort of remind me of the elder ...  \n",
       "1  the trans women read this tweet right now be b...  \n",
       "2  question these broads who criticize america wh...  \n",
       "3  it be about time for all illegals to go back t...  \n",
       "4  for starters bend over the one in pink and kic...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "20f5d21f-7c64-4766-9e5a-a6ecacd8c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../GRU_classif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6adc0020-f1bb-45a4-8e9d-6ed646ae904f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding/embeddings:0' shape=(39174, 50) dtype=float32, numpy=\n",
       " array([[-0.00197392, -0.04950519,  0.02095826, ...,  0.02697733,\n",
       "          0.0347213 ,  0.02741968],\n",
       "        [-0.07434124, -0.06303854, -0.02192898, ...,  0.02178095,\n",
       "          0.00758335,  0.0263961 ],\n",
       "        [ 0.03205993, -0.04147709,  0.03960084, ..., -0.05897377,\n",
       "          0.03714954, -0.05896284],\n",
       "        ...,\n",
       "        [ 0.004668  , -0.04208574, -0.038828  , ..., -0.00510353,\n",
       "         -0.00246674, -0.00635874],\n",
       "        [ 0.04527494,  0.03923582,  0.03357867, ...,  0.00486529,\n",
       "         -0.04217653,  0.01994053],\n",
       "        [ 0.00233836, -0.0066291 , -0.04963028, ...,  0.04997966,\n",
       "         -0.02780968, -0.03874063]], dtype=float32)>,\n",
       " <tf.Variable 'gru/gru_cell/kernel:0' shape=(50, 60) dtype=float32, numpy=\n",
       " array([[ 0.30962777,  0.07257307, -0.05396277, ...,  0.13521294,\n",
       "         -0.07545161,  0.00748688],\n",
       "        [ 0.08107282, -0.03717114,  0.02668694, ...,  0.10987555,\n",
       "         -0.04112379,  0.06729835],\n",
       "        [-0.16725013, -0.09027753,  0.1467643 , ..., -0.3282208 ,\n",
       "          0.26123288, -0.00114504],\n",
       "        ...,\n",
       "        [-0.19971395,  0.13868983, -0.02870173, ..., -0.12833558,\n",
       "         -0.13212855,  0.30631882],\n",
       "        [-0.06372417,  0.09083179, -0.04888981, ...,  0.0905328 ,\n",
       "          0.18934372, -0.37002987],\n",
       "        [ 0.03399349,  0.16300699,  0.02940842, ...,  0.375731  ,\n",
       "         -0.08669919, -0.03259915]], dtype=float32)>,\n",
       " <tf.Variable 'gru/gru_cell/recurrent_kernel:0' shape=(20, 60) dtype=float32, numpy=\n",
       " array([[-0.13445915,  0.32820547, -0.02126774, ...,  0.07992703,\n",
       "         -0.11099432, -0.30083102],\n",
       "        [-0.42995563, -0.18039782, -0.3883628 , ...,  0.15723649,\n",
       "         -0.37244916, -0.08188908],\n",
       "        [-0.06726784,  0.02390029,  0.11735342, ...,  0.17345159,\n",
       "          0.10544882,  0.01758091],\n",
       "        ...,\n",
       "        [-0.14984106, -0.26492083, -0.15660535, ..., -0.05869911,\n",
       "         -0.24912284, -0.00792506],\n",
       "        [ 0.30586   ,  0.00885759, -0.01885686, ...,  0.15153657,\n",
       "          0.06507832, -0.00103469],\n",
       "        [-0.05739063, -0.4540577 ,  0.1428042 , ..., -0.01919343,\n",
       "         -0.15015402,  0.02904163]], dtype=float32)>,\n",
       " <tf.Variable 'gru/gru_cell/bias:0' shape=(2, 60) dtype=float32, numpy=\n",
       " array([[ 0.21402942,  0.16756631, -0.24523452, -0.07703617, -0.03042739,\n",
       "         -0.1230592 ,  0.08579841, -0.19663644,  0.1138792 , -0.11583731,\n",
       "         -0.12934628, -0.2529589 , -0.3227658 , -0.23311284, -0.1310014 ,\n",
       "         -0.03048867, -0.06736475, -0.37164426, -0.06786116, -0.00615782,\n",
       "          0.17722724,  0.1799066 ,  0.1684039 ,  0.15442513,  0.00422185,\n",
       "          0.16272756,  0.11778492,  0.07225443,  0.12356167,  0.08381384,\n",
       "          0.1300753 ,  0.08129885,  0.113207  ,  0.09249596,  0.146533  ,\n",
       "          0.18991382,  0.11133654,  0.00204613,  0.1290674 ,  0.09731661,\n",
       "          0.0144252 , -0.03064735, -0.06732702, -0.04189856,  0.06813059,\n",
       "         -0.08553603, -0.11803828,  0.09413701,  0.02527385,  0.05382777,\n",
       "          0.00589207, -0.0811244 ,  0.03658321, -0.06871615,  0.01298681,\n",
       "         -0.00841922,  0.14224592, -0.04669739,  0.10369869, -0.02431261],\n",
       "        [ 0.21402942,  0.16756631, -0.24523452, -0.07703617, -0.03042739,\n",
       "         -0.1230592 ,  0.08579841, -0.19663644,  0.1138792 , -0.11583731,\n",
       "         -0.12934628, -0.2529589 , -0.3227658 , -0.23311284, -0.1310014 ,\n",
       "         -0.03048867, -0.06736475, -0.37164426, -0.06786116, -0.00615782,\n",
       "          0.17722724,  0.1799066 ,  0.1684039 ,  0.15442513,  0.00422185,\n",
       "          0.16272756,  0.11778492,  0.07225443,  0.12356167,  0.08381384,\n",
       "          0.1300753 ,  0.08129885,  0.113207  ,  0.09249596,  0.146533  ,\n",
       "          0.18991382,  0.11133654,  0.00204613,  0.1290674 ,  0.09731661,\n",
       "          0.01839951, -0.03087139, -0.05932332, -0.04273318,  0.07371416,\n",
       "         -0.08261501, -0.12392862,  0.1024081 ,  0.03312669,  0.0533985 ,\n",
       "          0.00620237, -0.08158309,  0.0381704 , -0.0677206 ,  0.00884125,\n",
       "         -0.02508326,  0.140237  , -0.04038238,  0.10266954, -0.03428443]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'gru_1/gru_cell/kernel:0' shape=(20, 60) dtype=float32, numpy=\n",
       " array([[ 0.17154607,  0.14955766, -0.00797991, ...,  0.13107316,\n",
       "          0.01549261, -0.02799976],\n",
       "        [-0.04687012, -0.01600574,  0.26885742, ..., -0.15884542,\n",
       "         -0.32100162, -0.44240072],\n",
       "        [ 0.01580215,  0.12758532,  0.31489012, ..., -0.22746278,\n",
       "          0.04938301,  0.42727324],\n",
       "        ...,\n",
       "        [ 0.03615628,  0.00079431,  0.10667872, ..., -0.40073863,\n",
       "          0.07192042, -0.45169216],\n",
       "        [-0.08734623,  0.09957337,  0.00285539, ...,  0.14705984,\n",
       "         -0.03215799,  0.1645817 ],\n",
       "        [-0.10343087, -0.05330019, -0.09200896, ..., -0.2699794 ,\n",
       "          0.23335357,  0.14253066]], dtype=float32)>,\n",
       " <tf.Variable 'gru_1/gru_cell/recurrent_kernel:0' shape=(20, 60) dtype=float32, numpy=\n",
       " array([[ 0.00742919, -0.1962311 , -0.3529007 , ..., -0.11000346,\n",
       "          0.01340121, -0.06800709],\n",
       "        [ 0.02776461, -0.21568154, -0.01659177, ..., -0.17238033,\n",
       "          0.03972843, -0.18533128],\n",
       "        [-0.21861146,  0.22579032, -0.05709887, ..., -0.43955293,\n",
       "          0.04069501, -0.20078819],\n",
       "        ...,\n",
       "        [ 0.15387937, -0.04484733, -0.26239577, ...,  0.35619786,\n",
       "          0.26636142, -0.0110972 ],\n",
       "        [-0.03793672, -0.10578897,  0.04830392, ...,  0.17674693,\n",
       "          0.19641685, -0.18344095],\n",
       "        [ 0.31366628, -0.19264264, -0.17657664, ..., -0.06235012,\n",
       "         -0.12426775,  0.17373131]], dtype=float32)>,\n",
       " <tf.Variable 'gru_1/gru_cell/bias:0' shape=(2, 60) dtype=float32, numpy=\n",
       " array([[-1.19611889e-01, -4.06156629e-01, -3.73973906e-01,\n",
       "         -1.65327936e-01, -1.77240074e-01, -2.42650062e-01,\n",
       "         -3.43368828e-01, -3.37490082e-01, -2.34153196e-01,\n",
       "         -3.54493976e-01, -2.62830913e-01, -4.92334455e-01,\n",
       "         -2.27488309e-01, -3.69908273e-01, -3.05437207e-01,\n",
       "         -2.47418255e-01, -1.13552816e-01, -3.92748386e-01,\n",
       "         -5.26059791e-02, -2.78270930e-01,  1.78414255e-01,\n",
       "          1.10695451e-01,  2.00335477e-02,  1.89855710e-01,\n",
       "          1.09321192e-01,  1.43849313e-01,  7.66488090e-02,\n",
       "          9.01756212e-02,  1.04792088e-01,  1.15571216e-01,\n",
       "          4.88638692e-02,  1.05267197e-01,  1.38914034e-01,\n",
       "          1.94289058e-01, -6.96991533e-02,  1.72626227e-01,\n",
       "         -7.38454610e-02,  1.81571156e-01, -4.19826247e-02,\n",
       "          1.11746743e-01,  3.58207315e-01, -1.48334214e-03,\n",
       "         -4.30810675e-02,  3.24745744e-01,  3.38575654e-02,\n",
       "          2.02420667e-01,  5.53947985e-02, -1.18829655e-02,\n",
       "          1.24250511e-02, -7.08777830e-02,  8.13207328e-02,\n",
       "         -2.14622682e-03, -3.13455433e-01,  4.14167106e-01,\n",
       "          1.74920663e-01,  2.07238607e-02,  1.56184927e-01,\n",
       "          3.22865658e-02, -5.90769239e-02, -9.15657170e-03],\n",
       "        [-1.19611889e-01, -4.06156629e-01, -3.73973906e-01,\n",
       "         -1.65327936e-01, -1.77240074e-01, -2.42650062e-01,\n",
       "         -3.43368828e-01, -3.37490082e-01, -2.34153196e-01,\n",
       "         -3.54493976e-01, -2.62830913e-01, -4.92334455e-01,\n",
       "         -2.27488309e-01, -3.69908273e-01, -3.05437207e-01,\n",
       "         -2.47418255e-01, -1.13552816e-01, -3.92748386e-01,\n",
       "         -5.26059791e-02, -2.78270930e-01,  1.78414255e-01,\n",
       "          1.10695451e-01,  2.00335477e-02,  1.89855710e-01,\n",
       "          1.09321192e-01,  1.43849313e-01,  7.66488090e-02,\n",
       "          9.01756212e-02,  1.04792088e-01,  1.15571216e-01,\n",
       "          4.88638692e-02,  1.05267197e-01,  1.38914034e-01,\n",
       "          1.94289058e-01, -6.96991533e-02,  1.72626227e-01,\n",
       "         -7.38454610e-02,  1.81571156e-01, -4.19826247e-02,\n",
       "          1.11746743e-01,  3.05991441e-01, -3.85174353e-04,\n",
       "         -6.83520362e-02,  2.89021283e-01,  3.91317084e-02,\n",
       "          2.18610257e-01,  6.82410076e-02, -7.71790836e-03,\n",
       "          3.74940503e-03, -7.85752758e-02,  4.93662097e-02,\n",
       "         -2.22874922e-03, -2.86712766e-01,  3.87462586e-01,\n",
       "          1.35616705e-01,  1.43052479e-02,  1.36732519e-01,\n",
       "          4.43883538e-02, -2.62951292e-02, -1.73369944e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(20, 6) dtype=float32, numpy=\n",
       " array([[-0.59214866, -0.24822742,  0.29047343, -0.13346136, -0.4968652 ,\n",
       "          0.27615735],\n",
       "        [ 0.49281234, -0.53170156, -0.8572336 ,  0.44172984,  0.40351313,\n",
       "          0.4604617 ],\n",
       "        [-0.38613787,  0.26084033, -0.20888397, -0.3812939 ,  0.4575616 ,\n",
       "          0.64972335],\n",
       "        [-0.5431262 , -0.15060712, -0.0466906 , -0.46247414, -0.20372745,\n",
       "         -0.560546  ],\n",
       "        [-0.8487032 ,  0.15403007,  0.11486975,  0.27326962, -0.05772943,\n",
       "          0.22400376],\n",
       "        [ 0.18656012, -0.7207673 , -0.69220805, -0.56662583, -0.22683214,\n",
       "         -0.18909138],\n",
       "        [ 0.54608756,  0.6289665 , -0.02703136, -0.03091311, -0.19988227,\n",
       "         -0.7754965 ],\n",
       "        [ 0.36534232,  0.6170282 , -0.16928896, -0.7700657 , -0.21554205,\n",
       "          0.56551045],\n",
       "        [-0.40126765, -0.11300706,  0.6846386 , -0.07136038, -0.19789082,\n",
       "          0.76961553],\n",
       "        [ 0.52018195, -0.17911148,  0.34423155, -0.5196903 , -0.4206627 ,\n",
       "         -0.40642938],\n",
       "        [-0.13229813, -0.67239416, -0.9029527 ,  0.0328727 , -0.2571572 ,\n",
       "         -0.56115365],\n",
       "        [ 0.6156012 ,  0.74806845,  0.11957183, -0.85175866,  0.47170842,\n",
       "         -0.49717057],\n",
       "        [-0.1600407 ,  0.5467736 ,  0.5662687 ,  0.5806621 ,  0.5839406 ,\n",
       "          0.01125996],\n",
       "        [-0.34607264, -0.685024  , -0.6650139 , -0.50018287, -0.3247542 ,\n",
       "         -0.4159136 ],\n",
       "        [-0.5681955 , -0.24294095, -0.7724614 , -0.28488988, -0.11581825,\n",
       "         -0.33341777],\n",
       "        [-0.3796667 ,  0.55573523, -0.13260746, -0.5934748 , -0.7747085 ,\n",
       "          0.1603083 ],\n",
       "        [-0.03189668, -0.28753865,  0.18253806, -0.30826348, -0.45404965,\n",
       "         -0.33837196],\n",
       "        [-0.10853462, -0.8510978 ,  0.66023266,  0.5963348 , -0.51827335,\n",
       "         -0.40127757],\n",
       "        [ 0.26635632, -0.42745966,  0.5370482 ,  0.69817346, -0.22703011,\n",
       "          0.70058954],\n",
       "        [ 0.25182727,  0.3872593 ,  0.03954194, -0.71384305, -0.54308313,\n",
       "         -0.391685  ]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(6,) dtype=float32, numpy=\n",
       " array([-0.20685622, -0.2310715 , -0.20983197, -0.17668481, -0.221109  ,\n",
       "        -0.12183727], dtype=float32)>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "df84a2ab-4122-46eb-974a-00399b93196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed=pd.read_csv('../data/labelling_dataset_v1.csv')\n",
    "\n",
    "# Split into training and testing data\n",
    "X = data_processed[\"text_processed\"]\n",
    "y = data_processed.drop(labels=[\"text_processed\", \"text\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "\n",
    "### Let's tokenize the vocabulary\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(X_train)\n",
    "vocab_size = len(tk.word_index)\n",
    "\n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tk.texts_to_sequences(X_train)\n",
    "X_test_token = tk.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post', maxlen = 180)\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post', maxlen = 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6385b65f-c2bf-4893-a111-b785d001047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325/1325 [==============================] - 37s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7336b4db-d5d0-4e42-bcef-19a264c0658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"Muslim people out of France\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ec591e70-317b-4fcf-ba3f-4def0ed54bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[4.6679188e-02 9.0563917e-01 3.6635421e-02 1.4836957e-04 4.0254677e-03\n",
      "  6.8724733e-03]]\n",
      "Religious Hate\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\"text\":[tweet]})\n",
    "data[\"text\"] = data[\"text\"].apply(cleaning_text)\n",
    "\n",
    "#tokenizer_bert\n",
    "X_pred=data[\"text\"]\n",
    "tk = joblib.load(\"../tokenizer.joblib\")\n",
    "X_pred_tok = tk.texts_to_sequences(X_pred)\n",
    "X_pred_pad = pad_sequences(X_pred_tok, dtype='float32', padding='post', maxlen = 180)\n",
    "y_pred = model.predict(X_pred_pad)\n",
    "\n",
    "probabilities = np.array(y_pred)\n",
    "df=pd.DataFrame(probabilities, columns=['Racist tweet','Religious Hate','Xenophobia','Misogyny','Transphobia','Homophobia'])\n",
    "print(probabilities)\n",
    "label = df.idxmax(axis=1).iloc[0]\n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "059cd229-4ee6-48da-94e9-7cc136723efb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2040346411.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[139], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    [[0.28474218 0.10841988 0.16050139 0.20107783 0.11093782 0.13432086]]\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "[[0.28474218 0.10841988 0.16050139 0.20107783 0.11093782 0.13432086]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f80b12-0f2d-45a6-a17e-ea8e41767dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd29ce-7500-43b2-a726-b7e321c63f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24e45e-1ef0-49da-9b83-7a2597b63662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866e8a56-de83-4479-924e-5adf9e385fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22d096-e285-47f3-a857-24ab8123ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = load_model('../CNN_classifv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1dc54-f574-4984-bd8f-d5e6046a7477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
