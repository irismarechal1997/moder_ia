{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d4db8d-a126-4dbd-afba-547339092021",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openAI\n",
      "  Obtaining dependency information for openAI from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/irismarechal/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages (from openAI) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/irismarechal/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages (from openAI) (4.66.1)\n",
      "Collecting aiohttp (from openAI)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/f3/56/a5a062bc98e8d5848f7790963771f8354f488726a59fd650742ca7391171/aiohttp-3.8.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.8.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/irismarechal/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages (from requests>=2.20->openAI) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/irismarechal/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages (from requests>=2.20->openAI) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/irismarechal/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages (from requests>=2.20->openAI) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/irismarechal/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages (from requests>=2.20->openAI) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/irismarechal/.pyenv/versions/3.10.6/envs/moder_ia/lib/python3.10/site-packages (from aiohttp->openAI) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openAI)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openAI)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openAI)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openAI)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/a3/5b/c785feda30d9fda8c1b1a11941e91253f59aeaf13e87ebe908d0f3f6c628/frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openAI)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.5-cp310-cp310-macosx_10_9_x86_64.whl (365 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.8/365.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-macosx_10_9_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openAI\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.0 multidict-6.0.4 openAI-0.28.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "! pip install openAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0efe5b-0d5c-478f-9036-480bab095b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d86aa3-ae51-4ebe-8076-88251430ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fb1d4f6-592d-4631-9133-cce267403045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Your tweet is racist and completely unacceptable. Discrimination and hate speech have severe consequences, including legal penalties and potential banning on this platform. We stand against such offensive behavior. #NoToRacism\"\n"
     ]
    }
   ],
   "source": [
    "classification = \"racist\"\n",
    "tweet = \"black people are dumb\"\n",
    "\n",
    "content_of_the_request = f\"We have received an offensive tweet. This tweet can be classified as {classification}. Please find here the tweet '{tweet}'. Could you please generate a response to this tweet by explaining that this tweet is {classification} and recall the potential penalties incurred (legally but also in terms of banning on the tweeter platform). Please generate a response in the form of a tweet of max 280 characters and directly generate the quoted response without anything else.\"\n",
    "\n",
    "response = openai.ChatCompletion.create(model='gpt-3.5-turbo', messages=[{'role':'user','content': content_of_the_request}])\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
